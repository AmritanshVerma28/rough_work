{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba797f65-2181-4461-b479-b3311f92dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21eca1af-57b7-4a20-8f29-e5c20a52740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_name = \"Phone call with HMRC fraudster in UK 2021.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89bb57cc-aac0-4056-8561-122c8a6bd1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "   # api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "\n",
    "def get_gpt_res(ip):\n",
    "    print(\"ip for gpt res \",ip)\n",
    "    print(\"start of gpt response\")\n",
    "    messages=[\n",
    "            {\"role\": \"system\",\n",
    "             \"content\": \"\"\"As a customer care professional, I want to analyze this audio transcript to detect any\n",
    "             anomalies or potential fraud\"\"\"},\n",
    "            {\"role\": \"user\", \"content\": ip}]\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=\"gpt-4o\",\n",
    "    )\n",
    "    res = chat_completion.choices[0].message.content\n",
    "    print(\"end of gpt response\")\n",
    "    print(\"response got is \"+str(res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04d749a8-2fb2-4e82-95d3-9cc8fd0e04a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import torch\n",
    "torch.cuda.is_available()\n",
    "\n",
    "# Load the model from the specified path\n",
    "model = whisper.load_model(\"F:/models/small.en.pt\",device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db29fb7b-5c46-4128-9cb7-8252617a1f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def extract_audio_segment(file_path,file_name, start_time, end_time):\n",
    "    \n",
    "    start_time = start_time*1000\n",
    "    end_time = end_time*1000\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(file_path+file_name)\n",
    "    \n",
    "    # Extract the segment\n",
    "    extracted_segment = audio[start_time:end_time]\n",
    "\n",
    "    new_file_name = file_path+f\"{start_time}_{end_time}_{file_name}\"\n",
    "    \n",
    "    # Save the extracted segment\n",
    "    extracted_segment.export(new_file_name, format=\"wav\")\n",
    "\n",
    "    return new_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e95fecba-d6f8-4957-a018-3df2f5236b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_op(path):\n",
    "    print(\"start of model_op\")\n",
    "    result = model.transcribe(path)\n",
    "    txt = result[\"text\"]\n",
    "    print(\"end of model_op\")\n",
    "    return result,txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db6ae6ea-c3d0-44f4-9410-a5e2fa4a4139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dictionary to store the linguistic markers information\n",
    "linguistic_markers = {\n",
    "    \"Causation\": {\n",
    "        \"description\": \"Providing a certain level of concreteness to an explanation.\",\n",
    "        \"words\": [\"Because\", \"Effect\", \"Hence\"]\n",
    "    },\n",
    "    \"Negation\": {\n",
    "        \"description\": \"Avoiding to provide a direct response.\",\n",
    "        \"words\": [\"No\", \"Not\", \"Can’t\", \"Didn’t\"]\n",
    "    },\n",
    "    \"Hedging\": {\n",
    "        \"description\": \"Describes words which meaning implicitly involves fuzziness.\",\n",
    "        \"words\": [\"May be\", \"I guess\", \"Sort of\"]\n",
    "    },\n",
    "    \"Qualified assertions\": {\n",
    "        \"description\": \"Unveils questionable actions.\",\n",
    "        \"words\": [\"Needed\", \"Attempted\"]\n",
    "    },\n",
    "    \"Temporal Lacunae\": {\n",
    "        \"description\": \"Unexplained lapses of time.\",\n",
    "        \"words\": [\"Later that day\", \"Afterwards\"]\n",
    "    },\n",
    "    \"Overzealous expression\": {\n",
    "        \"description\": \"Expresses some level of uncertainty.\",\n",
    "        \"words\": [\"I swear to God\", \"Honestly\"]\n",
    "    },\n",
    "    \"Memory loss\": {\n",
    "        \"description\": \"Feigning memory loss.\",\n",
    "        \"words\": [\"I forget\", \"Can’t remember\"]\n",
    "    },\n",
    "    \"Third person plural pronouns\": {\n",
    "        \"description\": \"Possessive determiners to refer to things or people other than the speaker.\",\n",
    "        \"words\": [\"They\", \"Them\", \"Theirs\"]\n",
    "    },\n",
    "    \"Pronouns\": {\n",
    "        \"description\": \"Possessive determiners to refer to the speaker by overemphasising their physical presence.\",\n",
    "        \"words\": [\"I\", \"Me\", \"Mine\"]\n",
    "    },\n",
    "    \"Negative emotion\": {\n",
    "        \"description\": \"Negative expressions in word choice.\",\n",
    "        \"words\": [\"Afraid\", \"Sad\", \"Hate\", \"Abandon\", \"Hurt\"]\n",
    "    },\n",
    "    \"Negative sentiment\": {\n",
    "        \"description\": \"Negative emotional effect.\",\n",
    "        \"words\": [\"Abominable\", \"Anger\", \"Anxious\", \"Bad\"]\n",
    "    },\n",
    "    \"Positive emotion\": {\n",
    "        \"description\": \"Positive expressions in word choice.\",\n",
    "        \"words\": [\"Happy\", \"Brave\", \"Love\", \"Nice\", \"Sweet\"]\n",
    "    },\n",
    "    \"Positive sentiment\": {\n",
    "        \"description\": \"Positive emotional effect.\",\n",
    "        \"words\": [\"Admire\", \"Amazing\", \"Assure\", \"Charm\"]\n",
    "    },\n",
    "    \"Disfluencies\": {\n",
    "        \"description\": \"Interruption in the flow of speech.\",\n",
    "        \"words\": [\"Uh\", \"Um\", \"You know\", \"Er\", \"Ah\"]\n",
    "    },\n",
    "    \"Self reference words\": {\n",
    "        \"description\": \"Deceivers tend to use fewer self-referencing expressions.\",\n",
    "        \"words\": [\"I\", \"My\", \"Mine\"]\n",
    "    },\n",
    "    \"Nominalised verbs\": {\n",
    "        \"description\": \"Nouns derived from verbs. Nominalisations tend to hide the real action.\",\n",
    "        \"words\": [\"Education\", \"Arrangement\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_features_2(txt):\n",
    "    op = \"\"\"Given below is a transcript enclosed in {} brackets. \n",
    "    The json below has category name as the key.\n",
    "    For each category name you are given \n",
    "    (a) certain words that fall into this category ('words')\n",
    "    (b) description of the category ('description')\n",
    "    \n",
    "    JSON : \n",
    "    \"\"\"+str(linguistic_markers)+\"\"\"\n",
    "    \n",
    "    1) For each category provide a dictionary of words along with its frequency of occurance in the transcript\n",
    "    2) calculate the overall sentiment of the transcript on a scale of -1 to +1 where -1 is extremely negative and +1 is extremely postive\n",
    "    \n",
    "    Give your response as json with keys as category name (as given in data) and 'sentiment'\n",
    "    \n",
    "    Transcript : {\"\"\"+txt+\"\"\"}\n",
    "    \n",
    "    Please Note it is very important that your response should be a valid json object directly readable using \n",
    "    json.loads()\n",
    "    Example response \n",
    "    {\n",
    "    'key1':'value1',\n",
    "    'key2':'value2',\n",
    "    'key3':'value3'\n",
    "    }\n",
    "    \"\"\"\n",
    "    r1 = get_gpt_res(op)\n",
    "    print(r1)\n",
    "    return r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e0453-9333-44e4-82d1-4c728986c512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55ac5358-b58a-4820-94d7-622df3bae3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cea1699-3909-4ec6-ab4d-fe8b7f5712d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import pyaudio\n",
    "import time\n",
    "import threading\n",
    "import keyboard\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b290d02-a2a7-49f9-a075-cba1255756dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_obj(d, description, value, name):\n",
    "    obj = {}\n",
    "    obj['description'] = description\n",
    "    obj['value'] = value\n",
    "    obj['name'] = name\n",
    "    d.append(obj)\n",
    "   # return d\n",
    "\n",
    "def get_features(y, sr):\n",
    "    print(\"len of y trunc is \"+str(len(y)))\n",
    "    print(\"get features start\")\n",
    "    d = []\n",
    "\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=y).T, axis=0)\n",
    "    description = \"Zero-Crossing Rate (ZCR): High ZCR indicates more frequent sign changes in the signal, capturing noisiness and abrupt changes in speech, which can signal stress or nervousness.\"\n",
    "    get_metric_obj(d, description, zcr[0], 'zero_crossing_rate')\n",
    "\n",
    "    rmse = np.mean(librosa.feature.rms(y=y).T, axis=0)\n",
    "    description = \"Root Mean Square Energy (RMSE): Measures the loudness of speech. Sudden changes or high energy can indicate emotional stress or intentional emphasis.\"\n",
    "    get_metric_obj(d, description, rmse[0], 'root_mean_square_energy')\n",
    "\n",
    "   # frame_length = 2048\n",
    "   # hop_length = 512\n",
    "   # energy = np.array([\n",
    "   #     sum(abs(y[i:i+frame_length]**2))\n",
    "   #     for i in range(0, len(y), hop_length)\n",
    "   # ])\n",
    "   # description = \"Short-Time Energy: Highlights bursts of sound and pauses, indicating unnatural or rehearsed speech patterns.\"\n",
    "   # get_metric_obj(d, description, np.mean(energy), 'short_time_energy')\n",
    "\n",
    "    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr).T, axis=0)\n",
    "    description = \"Spectral Centroid: Captures the center of mass of the spectrum, indicating the 'brightness' of the sound. Deviations from normal patterns can indicate emotional stress or emphasis.\"\n",
    "    get_metric_obj(d, description, spectral_centroid[0], 'spectral_centroid')\n",
    "\n",
    "    spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr).T, axis=0)\n",
    "    description = \"Spectral Bandwidth: Measures the range of frequencies. Wider bandwidth can indicate stressed speech or background noise.\"\n",
    "    get_metric_obj(d, description, spectral_bandwidth[0], 'spectral_bandwidth')\n",
    "\n",
    "    spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr).T, axis=0)\n",
    "    description = \"Spectral Roll-off: Helps to identify voiced vs. unvoiced sounds. Higher roll-off can indicate abrupt changes in speech patterns.\"\n",
    "    get_metric_obj(d, description, spectral_rolloff[0], 'spectral_rolloff')\n",
    "\n",
    "    pitches, magnitudes = librosa.core.piptrack(y=y, sr=sr)\n",
    "    pitch = []\n",
    "    for t in range(pitches.shape[1]):\n",
    "        index = magnitudes[:, t].argmax()\n",
    "        pitch.append(pitches[index, t])\n",
    "    pitch_mean = np.mean([p for p in pitch if p > 0])\n",
    "    description = \"Pitch: Variations in pitch can indicate emotional stress or intentional modulation used in deception.\"\n",
    "    get_metric_obj(d, description, pitch_mean, 'pitch')\n",
    "\n",
    " #   harmonic_to_noise_ratio = np.mean(librosa.effects.harmonic(y))\n",
    " #   description = \"Harmonics-to-Noise Ratio (HNR): Measures the ratio of harmonic sounds to noise. Lower HNR indicates more noise and potential stress in the voice.\"\n",
    " #   get_metric_obj(d, description, harmonic_to_noise_ratio, 'harmonic_to_noise_ratio')\n",
    "\n",
    "    intonation = np.std(pitches[pitches > 0])\n",
    "    description = \"Prosodic Features (e.g., intonation): Includes intonation, stress, and rhythm. Irregularities in these features can indicate emotional stress or rehearsed speech.\"\n",
    "    get_metric_obj(d, description, intonation, 'intonation')\n",
    "\n",
    "    duration = librosa.get_duration(y=y, sr=sr)\n",
    "    words = len(librosa.effects.split(y, top_db=20))\n",
    "    speaking_rate = words / duration\n",
    "    description = \"Speaking Rate: The rate of speech. Unnaturally fast or slow speaking rates can indicate nervousness or rehearsed speech.\"\n",
    "    get_metric_obj(d, description, speaking_rate, 'speaking_rate')\n",
    "    print(\"get features end\")\n",
    "  #  print(\"d -->\",d)\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cfcff3a-0228-4c1f-8d93-dc4e75c6f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "global dg\n",
    "dg = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbb821a9-728e-4d00-a328-fb859c5bf604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def string_to_json(sample_string):\n",
    "    sample_string = sample_string.replace(\"json\",\"\")\n",
    "    print(\"sample string is \",sample_string)\n",
    "    jl = json.loads(sample_string)\n",
    "    return jl\n",
    "\n",
    "def sum_values(string):\n",
    "    print(\"start of sum_values\")\n",
    "    data = string_to_json(string)\n",
    "    reduced_dict = {}\n",
    "    for key, sub_dict in data.items():\n",
    "        if isinstance(sub_dict, dict):\n",
    "            total_sum = sum(sub_dict.values())\n",
    "            reduced_dict[key] = float(total_sum)\n",
    "        else:\n",
    "            reduced_dict[key] = float(sub_dict)\n",
    "\n",
    "    print(\"end of sum_values\")\n",
    "    return reduced_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8449cf1f-73e5-4670-a176-3d5592b07db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_time_series_view(ds,fl):\n",
    "    print(\"inside get_time_series\")\n",
    "    global dg\n",
    "    for d in ds:\n",
    "        n = d['name']\n",
    "        if n not in dg.keys():\n",
    "            dg[n]=[d['value']]\n",
    "        else:\n",
    "            dg[n].append(d['value'])    \n",
    "\n",
    "  #  print(\"dg is -->\",dg)\n",
    "    df = pd.DataFrame(dg)\n",
    "    df = df.reset_index(inplace=False)\n",
    "    print(df.head())\n",
    "    plot_dataframe(df,fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06c716ca-1a04-4555-892a-5fe5d60f67d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "def plot_dataframe(df,fl):\n",
    "    print(\"plot_dataframes start\")\n",
    "    # Create the figure\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add a trace for each column except 'index'\n",
    "    for column in df.columns:\n",
    "        if column != 'index':\n",
    "            fig.add_trace(go.Scatter(x=df['index'], y=df[column], mode='lines', name=column))\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title='Plot of DataFrame Columns',\n",
    "        xaxis_title='Index',\n",
    "        yaxis_title='Values',\n",
    "        xaxis=dict(range=[0,fl+10]),\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    print(\"# Save the figure as an HTML file\")\n",
    "    fig.write_html(\"sample_plot.html\")\n",
    "    # Show the figure\n",
    "    #fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf5159bd-056f-448c-ad83-3a2a656733f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Global flag to stop the playback and thread\n",
    "stop_flag = False\n",
    "global ckp_count\n",
    "ckp_count = 0\n",
    "\n",
    "\n",
    "global fet2\n",
    "\n",
    "\n",
    "def make_my_fet2(ip):\n",
    "    pass\n",
    "# Function to play the wav file and call the get_features function every ckp seconds\n",
    "def play_wav_with_checkpoints(file_path, ckp):\n",
    "    global stop_flag\n",
    "\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "    # Open the .wav file\n",
    "    wf = wave.open(file_path, 'rb')\n",
    "\n",
    "    # Create a PyAudio instance\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # Open a stream to play the audio\n",
    "    stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                    channels=wf.getnchannels(),\n",
    "                    rate=wf.getframerate(),\n",
    "                    output=True)\n",
    "\n",
    "    # Read data in chunks\n",
    "    chunk = 1024\n",
    "    data = wf.readframes(chunk)\n",
    "\n",
    "    # Define a function to handle checkpoints\n",
    "    def checkpoint_handler():\n",
    "        print(\"pt\")\n",
    "        while not stop_flag:\n",
    "            time.sleep(ckp)\n",
    "            global ckp_count\n",
    "            ckp_count += 1\n",
    "            print(\"ckp_count is \",ckp_count)\n",
    "            if not stop_flag:\n",
    "                # Get the current time in the audio\n",
    "               # current_time = stream.get_time()\n",
    "                # Extract the current portion of the audio\n",
    "                print(\"y len is \"+str(len(y)))\n",
    "              #  print(\"current_time is \"+str(current_time)+\" sr is -->\"+str(sr))\n",
    "\n",
    "                fl  = len(y)/(ckp* sr)\n",
    "                y_current = y[:int(ckp_count*ckp* sr)]\n",
    "                features = get_features(y_current, sr)\n",
    "\n",
    "                 #Example usage:\n",
    "                new_file = extract_audio_segment(\"\",audio_file_name, 0,ckp_count*ckp )\n",
    "                print(f\"New file saved as: {new_file}\")\n",
    "\n",
    "                res,txt = get_model_op(new_file)\n",
    "                print(txt)\n",
    "                fet2 = get_features_2(txt)\n",
    "                fet2_pp = sum_values(fet2)\n",
    "                print(fet2_pp)\n",
    "                print(features)\n",
    "                get_time_series_view(features,fl)\n",
    "                print(features)\n",
    "\n",
    "    # Start the checkpoint handler in a separate thread\n",
    "    checkpoint_thread = threading.Thread(target=checkpoint_handler)\n",
    "    checkpoint_thread.daemon = True\n",
    "    checkpoint_thread.start()\n",
    "\n",
    "    # Function to stop the playback and thread\n",
    "    def stop_playback():\n",
    "        global stop_flag\n",
    "        stop_flag = True\n",
    "        print(\"Stopping playback and checkpoint handler...\")\n",
    "\n",
    "    # Set up the key listener for the \"Esc\" key\n",
    "    keyboard.add_hotkey('esc', stop_playback)\n",
    "\n",
    "    # Play the audio\n",
    "    while data and not stop_flag:\n",
    "        stream.write(data)\n",
    "        data = wf.readframes(chunk)\n",
    "\n",
    "    # Close the stream and PyAudio\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    print(\"Audio playback stopped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97670587-80ec-4823-89bb-324b7d630b15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt\n",
      "ckp_count is  1\n",
      "y len is 11956224\n",
      "len of y trunc is 882000\n",
      "get features start\n",
      "get features end\n",
      "New file saved as: 0_20000_Phone call with HMRC fraudster in UK 2021.wav\n",
      "start of model_op\n",
      "end of model_op\n",
      " There is a criminal case that is listed under your name for tax fraud and tax evasion and there is also a warrant out for your arrest now. There's a warrant out for my arrest. This is a recordable line sir. I have to play this recording in the court also. We don't need any interruption in this court. Sorry this is going to get played in court. Yeah the recording is going to be in court.\n",
      "ip for gpt res  Given below is a transcript enclosed in {} brackets. \n",
      "    The json below has category name as the key.\n",
      "    For each category name you are given \n",
      "    (a) certain words that fall into this category ('words')\n",
      "    (b) description of the category ('description')\n",
      "    \n",
      "    JSON : \n",
      "    {'Causation': {'description': 'Providing a certain level of concreteness to an explanation.', 'words': ['Because', 'Effect', 'Hence']}, 'Negation': {'description': 'Avoiding to provide a direct response.', 'words': ['No', 'Not', 'Can’t', 'Didn’t']}, 'Hedging': {'description': 'Describes words which meaning implicitly involves fuzziness.', 'words': ['May be', 'I guess', 'Sort of']}, 'Qualified assertions': {'description': 'Unveils questionable actions.', 'words': ['Needed', 'Attempted']}, 'Temporal Lacunae': {'description': 'Unexplained lapses of time.', 'words': ['Later that day', 'Afterwards']}, 'Overzealous expression': {'description': 'Expresses some level of uncertainty.', 'words': ['I swear to God', 'Honestly']}, 'Memory loss': {'description': 'Feigning memory loss.', 'words': ['I forget', 'Can’t remember']}, 'Third person plural pronouns': {'description': 'Possessive determiners to refer to things or people other than the speaker.', 'words': ['They', 'Them', 'Theirs']}, 'Pronouns': {'description': 'Possessive determiners to refer to the speaker by overemphasising their physical presence.', 'words': ['I', 'Me', 'Mine']}, 'Negative emotion': {'description': 'Negative expressions in word choice.', 'words': ['Afraid', 'Sad', 'Hate', 'Abandon', 'Hurt']}, 'Negative sentiment': {'description': 'Negative emotional effect.', 'words': ['Abominable', 'Anger', 'Anxious', 'Bad']}, 'Positive emotion': {'description': 'Positive expressions in word choice.', 'words': ['Happy', 'Brave', 'Love', 'Nice', 'Sweet']}, 'Positive sentiment': {'description': 'Positive emotional effect.', 'words': ['Admire', 'Amazing', 'Assure', 'Charm']}, 'Disfluencies': {'description': 'Interruption in the flow of speech.', 'words': ['Uh', 'Um', 'You know', 'Er', 'Ah']}, 'Self reference words': {'description': 'Deceivers tend to use fewer self-referencing expressions.', 'words': ['I', 'My', 'Mine']}, 'Nominalised verbs': {'description': 'Nouns derived from verbs. Nominalisations tend to hide the real action.', 'words': ['Education', 'Arrangement']}}\n",
      "    \n",
      "    1) For each category provide a dictionary of words along with its frequency of occurance in the transcript\n",
      "    2) calculate the overall sentiment of the transcript on a scale of -1 to +1 where -1 is extremely negative and +1 is extremely postive\n",
      "    \n",
      "    Give your response as json with keys as category name (as given in data) and 'sentiment'\n",
      "    \n",
      "    Transcript : { There is a criminal case that is listed under your name for tax fraud and tax evasion and there is also a warrant out for your arrest now. There's a warrant out for my arrest. This is a recordable line sir. I have to play this recording in the court also. We don't need any interruption in this court. Sorry this is going to get played in court. Yeah the recording is going to be in court.}\n",
      "    \n",
      "    Please Note it is very important that your response should be a valid json object directly readable using \n",
      "    json.loads()\n",
      "    Example response \n",
      "    {\n",
      "    'key1':'value1',\n",
      "    'key2':'value2',\n",
      "    'key3':'value3'\n",
      "    }\n",
      "    \n",
      "start of gpt response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7 (checkpoint_handler):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\amrit\\.conda\\envs\\personalEnv2\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\amrit\\.conda\\envs\\personalEnv2\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\amrit\\AppData\\Local\\Temp\\ipykernel_28576\\3664538408.py\", line 61, in checkpoint_handler\n",
      "  File \"C:\\Users\\amrit\\AppData\\Local\\Temp\\ipykernel_28576\\816564092.py\", line 11, in sum_values\n",
      "  File \"C:\\Users\\amrit\\AppData\\Local\\Temp\\ipykernel_28576\\816564092.py\", line 6, in string_to_json\n",
      "  File \"C:\\Users\\amrit\\.conda\\envs\\personalEnv2\\Lib\\json\\__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\amrit\\.conda\\envs\\personalEnv2\\Lib\\json\\decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\amrit\\.conda\\envs\\personalEnv2\\Lib\\json\\decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end of gpt response\n",
      "response got is ```json\n",
      "{\n",
      "    \"Causation\": {\n",
      "        \"Because\": 0,\n",
      "        \"Effect\": 0,\n",
      "        \"Hence\": 0\n",
      "    },\n",
      "    \"Negation\": {\n",
      "        \"No\": 0,\n",
      "        \"Not\": 1,\n",
      "        \"Can’t\": 0,\n",
      "        \"Didn’t\": 0\n",
      "    },\n",
      "    \"Hedging\": {\n",
      "        \"May be\": 0,\n",
      "        \"I guess\": 0,\n",
      "        \"Sort of\": 0\n",
      "    },\n",
      "    \"Qualified assertions\": {\n",
      "        \"Needed\": 0,\n",
      "        \"Attempted\": 0\n",
      "    },\n",
      "    \"Temporal Lacunae\": {\n",
      "        \"Later that day\": 0,\n",
      "        \"Afterwards\": 0\n",
      "    },\n",
      "    \"Overzealous expression\": {\n",
      "        \"I swear to God\": 0,\n",
      "        \"Honestly\": 0\n",
      "    },\n",
      "    \"Memory loss\": {\n",
      "        \"I forget\": 0,\n",
      "        \"Can’t remember\": 0\n",
      "    },\n",
      "    \"Third person plural pronouns\": {\n",
      "        \"They\": 0,\n",
      "        \"Them\": 0,\n",
      "        \"Theirs\": 0\n",
      "    },\n",
      "    \"Pronouns\": {\n",
      "        \"I\": 2,\n",
      "        \"Me\": 0,\n",
      "        \"Mine\": 0\n",
      "    },\n",
      "    \"Negative emotion\": {\n",
      "        \"Afraid\": 0,\n",
      "        \"Sad\": 0,\n",
      "        \"Hate\": 0,\n",
      "        \"Abandon\": 0,\n",
      "        \"Hurt\": 0\n",
      "    },\n",
      "    \"Negative sentiment\": {\n",
      "        \"Abominable\": 0,\n",
      "        \"Anger\": 0,\n",
      "        \"Anxious\": 0,\n",
      "        \"Bad\": 0\n",
      "    },\n",
      "    \"Positive emotion\": {\n",
      "        \"Happy\": 0,\n",
      "        \"Brave\": 0,\n",
      "        \"Love\": 0,\n",
      "        \"Nice\": 0,\n",
      "        \"Sweet\": 0\n",
      "    },\n",
      "    \"Positive sentiment\": {\n",
      "        \"Admire\": 0,\n",
      "        \"Amazing\": 0,\n",
      "        \"Assure\": 0,\n",
      "        \"Charm\": 0\n",
      "    },\n",
      "    \"Disfluencies\": {\n",
      "        \"Uh\": 0,\n",
      "        \"Um\": 0,\n",
      "        \"You know\": 0,\n",
      "        \"Er\": 0,\n",
      "        \"Ah\": 0\n",
      "    },\n",
      "    \"Self reference words\": {\n",
      "        \"I\": 2,\n",
      "        \"My\": 1,\n",
      "        \"Mine\": 0\n",
      "    },\n",
      "    \"Nominalised verbs\": {\n",
      "        \"Education\": 0,\n",
      "        \"Arrangement\": 0\n",
      "    },\n",
      "    \"sentiment\": -0.6\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "    \"Causation\": {\n",
      "        \"Because\": 0,\n",
      "        \"Effect\": 0,\n",
      "        \"Hence\": 0\n",
      "    },\n",
      "    \"Negation\": {\n",
      "        \"No\": 0,\n",
      "        \"Not\": 1,\n",
      "        \"Can’t\": 0,\n",
      "        \"Didn’t\": 0\n",
      "    },\n",
      "    \"Hedging\": {\n",
      "        \"May be\": 0,\n",
      "        \"I guess\": 0,\n",
      "        \"Sort of\": 0\n",
      "    },\n",
      "    \"Qualified assertions\": {\n",
      "        \"Needed\": 0,\n",
      "        \"Attempted\": 0\n",
      "    },\n",
      "    \"Temporal Lacunae\": {\n",
      "        \"Later that day\": 0,\n",
      "        \"Afterwards\": 0\n",
      "    },\n",
      "    \"Overzealous expression\": {\n",
      "        \"I swear to God\": 0,\n",
      "        \"Honestly\": 0\n",
      "    },\n",
      "    \"Memory loss\": {\n",
      "        \"I forget\": 0,\n",
      "        \"Can’t remember\": 0\n",
      "    },\n",
      "    \"Third person plural pronouns\": {\n",
      "        \"They\": 0,\n",
      "        \"Them\": 0,\n",
      "        \"Theirs\": 0\n",
      "    },\n",
      "    \"Pronouns\": {\n",
      "        \"I\": 2,\n",
      "        \"Me\": 0,\n",
      "        \"Mine\": 0\n",
      "    },\n",
      "    \"Negative emotion\": {\n",
      "        \"Afraid\": 0,\n",
      "        \"Sad\": 0,\n",
      "        \"Hate\": 0,\n",
      "        \"Abandon\": 0,\n",
      "        \"Hurt\": 0\n",
      "    },\n",
      "    \"Negative sentiment\": {\n",
      "        \"Abominable\": 0,\n",
      "        \"Anger\": 0,\n",
      "        \"Anxious\": 0,\n",
      "        \"Bad\": 0\n",
      "    },\n",
      "    \"Positive emotion\": {\n",
      "        \"Happy\": 0,\n",
      "        \"Brave\": 0,\n",
      "        \"Love\": 0,\n",
      "        \"Nice\": 0,\n",
      "        \"Sweet\": 0\n",
      "    },\n",
      "    \"Positive sentiment\": {\n",
      "        \"Admire\": 0,\n",
      "        \"Amazing\": 0,\n",
      "        \"Assure\": 0,\n",
      "        \"Charm\": 0\n",
      "    },\n",
      "    \"Disfluencies\": {\n",
      "        \"Uh\": 0,\n",
      "        \"Um\": 0,\n",
      "        \"You know\": 0,\n",
      "        \"Er\": 0,\n",
      "        \"Ah\": 0\n",
      "    },\n",
      "    \"Self reference words\": {\n",
      "        \"I\": 2,\n",
      "        \"My\": 1,\n",
      "        \"Mine\": 0\n",
      "    },\n",
      "    \"Nominalised verbs\": {\n",
      "        \"Education\": 0,\n",
      "        \"Arrangement\": 0\n",
      "    },\n",
      "    \"sentiment\": -0.6\n",
      "}\n",
      "```\n",
      "start of sum_values\n",
      "sample string is  ```\n",
      "{\n",
      "    \"Causation\": {\n",
      "        \"Because\": 0,\n",
      "        \"Effect\": 0,\n",
      "        \"Hence\": 0\n",
      "    },\n",
      "    \"Negation\": {\n",
      "        \"No\": 0,\n",
      "        \"Not\": 1,\n",
      "        \"Can’t\": 0,\n",
      "        \"Didn’t\": 0\n",
      "    },\n",
      "    \"Hedging\": {\n",
      "        \"May be\": 0,\n",
      "        \"I guess\": 0,\n",
      "        \"Sort of\": 0\n",
      "    },\n",
      "    \"Qualified assertions\": {\n",
      "        \"Needed\": 0,\n",
      "        \"Attempted\": 0\n",
      "    },\n",
      "    \"Temporal Lacunae\": {\n",
      "        \"Later that day\": 0,\n",
      "        \"Afterwards\": 0\n",
      "    },\n",
      "    \"Overzealous expression\": {\n",
      "        \"I swear to God\": 0,\n",
      "        \"Honestly\": 0\n",
      "    },\n",
      "    \"Memory loss\": {\n",
      "        \"I forget\": 0,\n",
      "        \"Can’t remember\": 0\n",
      "    },\n",
      "    \"Third person plural pronouns\": {\n",
      "        \"They\": 0,\n",
      "        \"Them\": 0,\n",
      "        \"Theirs\": 0\n",
      "    },\n",
      "    \"Pronouns\": {\n",
      "        \"I\": 2,\n",
      "        \"Me\": 0,\n",
      "        \"Mine\": 0\n",
      "    },\n",
      "    \"Negative emotion\": {\n",
      "        \"Afraid\": 0,\n",
      "        \"Sad\": 0,\n",
      "        \"Hate\": 0,\n",
      "        \"Abandon\": 0,\n",
      "        \"Hurt\": 0\n",
      "    },\n",
      "    \"Negative sentiment\": {\n",
      "        \"Abominable\": 0,\n",
      "        \"Anger\": 0,\n",
      "        \"Anxious\": 0,\n",
      "        \"Bad\": 0\n",
      "    },\n",
      "    \"Positive emotion\": {\n",
      "        \"Happy\": 0,\n",
      "        \"Brave\": 0,\n",
      "        \"Love\": 0,\n",
      "        \"Nice\": 0,\n",
      "        \"Sweet\": 0\n",
      "    },\n",
      "    \"Positive sentiment\": {\n",
      "        \"Admire\": 0,\n",
      "        \"Amazing\": 0,\n",
      "        \"Assure\": 0,\n",
      "        \"Charm\": 0\n",
      "    },\n",
      "    \"Disfluencies\": {\n",
      "        \"Uh\": 0,\n",
      "        \"Um\": 0,\n",
      "        \"You know\": 0,\n",
      "        \"Er\": 0,\n",
      "        \"Ah\": 0\n",
      "    },\n",
      "    \"Self reference words\": {\n",
      "        \"I\": 2,\n",
      "        \"My\": 1,\n",
      "        \"Mine\": 0\n",
      "    },\n",
      "    \"Nominalised verbs\": {\n",
      "        \"Education\": 0,\n",
      "        \"Arrangement\": 0\n",
      "    },\n",
      "    \"sentiment\": -0.6\n",
      "}\n",
      "```\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m      2\u001b[0m ckp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m  \u001b[38;5;66;03m# Duration in seconds\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mplay_wav_with_checkpoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckp\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 83\u001b[0m, in \u001b[0;36mplay_wav_with_checkpoints\u001b[1;34m(file_path, ckp)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Play the audio\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stop_flag:\n\u001b[1;32m---> 83\u001b[0m     \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m     data \u001b[38;5;241m=\u001b[39m wf\u001b[38;5;241m.\u001b[39mreadframes(chunk)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Close the stream and PyAudio\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\personalEnv2\\Lib\\site-packages\\pyaudio\\__init__.py:550\u001b[0m, in \u001b[0;36mPyAudio.Stream.write\u001b[1;34m(self, frames, num_frames, exception_on_underflow)\u001b[0m\n\u001b[0;32m    547\u001b[0m     width \u001b[38;5;241m=\u001b[39m get_sample_size(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format)\n\u001b[0;32m    548\u001b[0m     num_frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(frames) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channels \u001b[38;5;241m*\u001b[39m width))\n\u001b[1;32m--> 550\u001b[0m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m                \u001b[49m\u001b[43mexception_on_underflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "ckp = 20  # Duration in seconds\n",
    "play_wav_with_checkpoints(audio_file_name, ckp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5e1bd3b-c531-4311-8d74-f6b3412b7deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ip for gpt res  Given below is a transcript enclosed in {} brackets. \n",
      "    The json below has category name as the key.\n",
      "    For each category name you are given \n",
      "    (a) certain words that fall into this category ('words')\n",
      "    (b) description of the category ('description')\n",
      "    \n",
      "    JSON : \n",
      "    {'Causation': {'description': 'Providing a certain level of concreteness to an explanation.', 'words': ['Because', 'Effect', 'Hence']}, 'Negation': {'description': 'Avoiding to provide a direct response.', 'words': ['No', 'Not', 'Can’t', 'Didn’t']}, 'Hedging': {'description': 'Describes words which meaning implicitly involves fuzziness.', 'words': ['May be', 'I guess', 'Sort of']}, 'Qualified assertions': {'description': 'Unveils questionable actions.', 'words': ['Needed', 'Attempted']}, 'Temporal Lacunae': {'description': 'Unexplained lapses of time.', 'words': ['Later that day', 'Afterwards']}, 'Overzealous expression': {'description': 'Expresses some level of uncertainty.', 'words': ['I swear to God', 'Honestly']}, 'Memory loss': {'description': 'Feigning memory loss.', 'words': ['I forget', 'Can’t remember']}, 'Third person plural pronouns': {'description': 'Possessive determiners to refer to things or people other than the speaker.', 'words': ['They', 'Them', 'Theirs']}, 'Pronouns': {'description': 'Possessive determiners to refer to the speaker by overemphasising their physical presence.', 'words': ['I', 'Me', 'Mine']}, 'Negative emotion': {'description': 'Negative expressions in word choice.', 'words': ['Afraid', 'Sad', 'Hate', 'Abandon', 'Hurt']}, 'Negative sentiment': {'description': 'Negative emotional effect.', 'words': ['Abominable', 'Anger', 'Anxious', 'Bad']}, 'Positive emotion': {'description': 'Positive expressions in word choice.', 'words': ['Happy', 'Brave', 'Love', 'Nice', 'Sweet']}, 'Positive sentiment': {'description': 'Positive emotional effect.', 'words': ['Admire', 'Amazing', 'Assure', 'Charm']}, 'Disfluencies': {'description': 'Interruption in the flow of speech.', 'words': ['Uh', 'Um', 'You know', 'Er', 'Ah']}, 'Self reference words': {'description': 'Deceivers tend to use fewer self-referencing expressions.', 'words': ['I', 'My', 'Mine']}, 'Nominalised verbs': {'description': 'Nouns derived from verbs. Nominalisations tend to hide the real action.', 'words': ['Education', 'Arrangement']}}\n",
      "    \n",
      "    1) For each category provide a dictionary of words along with its frequency of occurance in the transcript\n",
      "    2) calculate the overall sentiment of the transcript on a scale of -1 to +1 where -1 is extremely negative and +1 is extremely postive\n",
      "    \n",
      "    Give your response as json with keys as category name (as given in data) and 'sentiment'\n",
      "    \n",
      "    Transcript : {Given below is a transcript enclosed in {} brackets. \n",
      "    The json below has category name as the key.\n",
      "    For each category name you are given \n",
      "    (a) certain words that fall into this category ('words')\n",
      "    (b) description of the category ('description')\n",
      "    \n",
      "    JSON : \n",
      "    {'Causation': {'description': 'Providing a certain level of concreteness to an explanation.', 'words': ['Because', 'Effect', 'Hence']}, 'Negation': {'description': 'Avoiding to provide a direct response.', 'words': ['No', 'Not', 'Can’t', 'Didn’t']}, 'Hedging': {'description': 'Describes words which meaning implicitly involves fuzziness.', 'words': ['May be', 'I guess', 'Sort of']}, 'Qualified assertions': {'description': 'Unveils questionable actions.', 'words': ['Needed', 'Attempted']}, 'Temporal Lacunae': {'description': 'Unexplained lapses of time.', 'words': ['Later that day', 'Afterwards']}, 'Overzealous expression': {'description': 'Expresses some level of uncertainty.', 'words': ['I swear to God', 'Honestly']}, 'Memory loss': {'description': 'Feigning memory loss.', 'words': ['I forget', 'Can’t remember']}, 'Third person plural pronouns': {'description': 'Possessive determiners to refer to things or people other than the speaker.', 'words': ['They', 'Them', 'Theirs']}, 'Pronouns': {'description': 'Possessive determiners to refer to the speaker by overemphasising their physical presence.', 'words': ['I', 'Me', 'Mine']}, 'Negative emotion': {'description': 'Negative expressions in word choice.', 'words': ['Afraid', 'Sad', 'Hate', 'Abandon', 'Hurt']}, 'Negative sentiment': {'description': 'Negative emotional effect.', 'words': ['Abominable', 'Anger', 'Anxious', 'Bad']}, 'Positive emotion': {'description': 'Positive expressions in word choice.', 'words': ['Happy', 'Brave', 'Love', 'Nice', 'Sweet']}, 'Positive sentiment': {'description': 'Positive emotional effect.', 'words': ['Admire', 'Amazing', 'Assure', 'Charm']}, 'Disfluencies': {'description': 'Interruption in the flow of speech.', 'words': ['Uh', 'Um', 'You know', 'Er', 'Ah']}, 'Self reference words': {'description': 'Deceivers tend to use fewer self-referencing expressions.', 'words': ['I', 'My', 'Mine']}, 'Nominalised verbs': {'description': 'Nouns derived from verbs. Nominalisations tend to hide the real action.', 'words': ['Education', 'Arrangement']}}\n",
      "    \n",
      "    1) For each category provide a dictionary of words along with its frequency of occurance in the transcript\n",
      "    2) calculate the overall sentiment of the transcript on a scale of -1 to +1 where -1 is extremely negative and +1 is extremely postive\n",
      "    \n",
      "    Give your response as json with keys as category name (as given in data) and 'sentiment'\n",
      "    \n",
      "    Transcript : { There is a criminal case that is listed under your name for tax fraud and tax evasion and there is also a warrant out for your arrest now. There's a warrant out for my arrest. This is a recordable line sir. I have to play this recording in the court also. We don't need any interruption in this court. Sorry this is going to get played in court. Yeah the recording is going to be in court.}\n",
      "    \n",
      "    Please Note it is very important that your response should be a valid json object directly readable using \n",
      "    json.loads()\n",
      "    Example response \n",
      "    {\n",
      "    'key1':'value1',\n",
      "    'key2':'value2',\n",
      "    'key3':'value3'\n",
      "    }}\n",
      "    \n",
      "    Please Note it is very important that your response should be a valid json object directly readable using \n",
      "    json.loads()\n",
      "    Example response \n",
      "    {\n",
      "    'key1':'value1',\n",
      "    'key2':'value2',\n",
      "    'key3':'value3'\n",
      "    }\n",
      "    \n",
      "start of gpt response\n",
      "end of gpt response\n",
      "response got is ```json\n",
      "{\n",
      "    \"Causation\": {\n",
      "        \"Because\": 0,\n",
      "        \"Effect\": 0,\n",
      "        \"Hence\": 0\n",
      "    },\n",
      "    \"Negation\": {\n",
      "        \"No\": 0,\n",
      "        \"Not\": 1,\n",
      "        \"Can’t\": 0,\n",
      "        \"Didn’t\": 0\n",
      "    },\n",
      "    \"Hedging\": {\n",
      "        \"May be\": 0,\n",
      "        \"I guess\": 0,\n",
      "        \"Sort of\": 0\n",
      "    },\n",
      "    \"Qualified assertions\": {\n",
      "        \"Needed\": 0,\n",
      "        \"Attempted\": 0\n",
      "    },\n",
      "    \"Temporal Lacunae\": {\n",
      "        \"Later that day\": 0,\n",
      "        \"Afterwards\": 0\n",
      "    },\n",
      "    \"Overzealous expression\": {\n",
      "        \"I swear to God\": 0,\n",
      "        \"Honestly\": 0\n",
      "    },\n",
      "    \"Memory loss\": {\n",
      "        \"I forget\": 0,\n",
      "        \"Can’t remember\": 0\n",
      "    },\n",
      "    \"Third person plural pronouns\": {\n",
      "        \"They\": 0,\n",
      "        \"Them\": 0,\n",
      "        \"Theirs\": 0\n",
      "    },\n",
      "    \"Pronouns\": {\n",
      "        \"I\": 3,\n",
      "        \"Me\": 1,\n",
      "        \"Mine\": 0\n",
      "    },\n",
      "    \"Negative emotion\": {\n",
      "        \"Afraid\": 0,\n",
      "        \"Sad\": 0,\n",
      "        \"Hate\": 0,\n",
      "        \"Abandon\": 0,\n",
      "        \"Hurt\": 0\n",
      "    },\n",
      "    \"Negative sentiment\": {\n",
      "        \"Abominable\": 0,\n",
      "        \"Anger\": 0,\n",
      "        \"Anxious\": 0,\n",
      "        \"Bad\": 0\n",
      "    },\n",
      "    \"Positive emotion\": {\n",
      "        \"Happy\": 0,\n",
      "        \"Brave\": 0,\n",
      "        \"Love\": 0,\n",
      "        \"Nice\": 0,\n",
      "        \"Sweet\": 0\n",
      "    },\n",
      "    \"Positive sentiment\": {\n",
      "        \"Admire\": 0,\n",
      "        \"Amazing\": 0,\n",
      "        \"Assure\": 0,\n",
      "        \"Charm\": 0\n",
      "    },\n",
      "    \"Disfluencies\": {\n",
      "        \"Uh\": 0,\n",
      "        \"Um\": 0,\n",
      "        \"You know\": 0,\n",
      "        \"Er\": 0,\n",
      "        \"Ah\": 0\n",
      "    },\n",
      "    \"Self reference words\": {\n",
      "        \"I\": 3,\n",
      "        \"My\": 1,\n",
      "        \"Mine\": 0\n",
      "    },\n",
      "    \"Nominalised verbs\": {\n",
      "        \"Education\": 0,\n",
      "        \"Arrangement\": 0\n",
      "    },\n",
      "    \"sentiment\": -0.7\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "    \"Causation\": {\n",
      "        \"Because\": 0,\n",
      "        \"Effect\": 0,\n",
      "        \"Hence\": 0\n",
      "    },\n",
      "    \"Negation\": {\n",
      "        \"No\": 0,\n",
      "        \"Not\": 1,\n",
      "        \"Can’t\": 0,\n",
      "        \"Didn’t\": 0\n",
      "    },\n",
      "    \"Hedging\": {\n",
      "        \"May be\": 0,\n",
      "        \"I guess\": 0,\n",
      "        \"Sort of\": 0\n",
      "    },\n",
      "    \"Qualified assertions\": {\n",
      "        \"Needed\": 0,\n",
      "        \"Attempted\": 0\n",
      "    },\n",
      "    \"Temporal Lacunae\": {\n",
      "        \"Later that day\": 0,\n",
      "        \"Afterwards\": 0\n",
      "    },\n",
      "    \"Overzealous expression\": {\n",
      "        \"I swear to God\": 0,\n",
      "        \"Honestly\": 0\n",
      "    },\n",
      "    \"Memory loss\": {\n",
      "        \"I forget\": 0,\n",
      "        \"Can’t remember\": 0\n",
      "    },\n",
      "    \"Third person plural pronouns\": {\n",
      "        \"They\": 0,\n",
      "        \"Them\": 0,\n",
      "        \"Theirs\": 0\n",
      "    },\n",
      "    \"Pronouns\": {\n",
      "        \"I\": 3,\n",
      "        \"Me\": 1,\n",
      "        \"Mine\": 0\n",
      "    },\n",
      "    \"Negative emotion\": {\n",
      "        \"Afraid\": 0,\n",
      "        \"Sad\": 0,\n",
      "        \"Hate\": 0,\n",
      "        \"Abandon\": 0,\n",
      "        \"Hurt\": 0\n",
      "    },\n",
      "    \"Negative sentiment\": {\n",
      "        \"Abominable\": 0,\n",
      "        \"Anger\": 0,\n",
      "        \"Anxious\": 0,\n",
      "        \"Bad\": 0\n",
      "    },\n",
      "    \"Positive emotion\": {\n",
      "        \"Happy\": 0,\n",
      "        \"Brave\": 0,\n",
      "        \"Love\": 0,\n",
      "        \"Nice\": 0,\n",
      "        \"Sweet\": 0\n",
      "    },\n",
      "    \"Positive sentiment\": {\n",
      "        \"Admire\": 0,\n",
      "        \"Amazing\": 0,\n",
      "        \"Assure\": 0,\n",
      "        \"Charm\": 0\n",
      "    },\n",
      "    \"Disfluencies\": {\n",
      "        \"Uh\": 0,\n",
      "        \"Um\": 0,\n",
      "        \"You know\": 0,\n",
      "        \"Er\": 0,\n",
      "        \"Ah\": 0\n",
      "    },\n",
      "    \"Self reference words\": {\n",
      "        \"I\": 3,\n",
      "        \"My\": 1,\n",
      "        \"Mine\": 0\n",
      "    },\n",
      "    \"Nominalised verbs\": {\n",
      "        \"Education\": 0,\n",
      "        \"Arrangement\": 0\n",
      "    },\n",
      "    \"sentiment\": -0.7\n",
      "}\n",
      "```\n",
      "start of sum_values\n",
      "sample string is  ```\n",
      "{\n",
      "    \"Causation\": {\n",
      "        \"Because\": 0,\n",
      "        \"Effect\": 0,\n",
      "        \"Hence\": 0\n",
      "    },\n",
      "    \"Negation\": {\n",
      "        \"No\": 0,\n",
      "        \"Not\": 1,\n",
      "        \"Can’t\": 0,\n",
      "        \"Didn’t\": 0\n",
      "    },\n",
      "    \"Hedging\": {\n",
      "        \"May be\": 0,\n",
      "        \"I guess\": 0,\n",
      "        \"Sort of\": 0\n",
      "    },\n",
      "    \"Qualified assertions\": {\n",
      "        \"Needed\": 0,\n",
      "        \"Attempted\": 0\n",
      "    },\n",
      "    \"Temporal Lacunae\": {\n",
      "        \"Later that day\": 0,\n",
      "        \"Afterwards\": 0\n",
      "    },\n",
      "    \"Overzealous expression\": {\n",
      "        \"I swear to God\": 0,\n",
      "        \"Honestly\": 0\n",
      "    },\n",
      "    \"Memory loss\": {\n",
      "        \"I forget\": 0,\n",
      "        \"Can’t remember\": 0\n",
      "    },\n",
      "    \"Third person plural pronouns\": {\n",
      "        \"They\": 0,\n",
      "        \"Them\": 0,\n",
      "        \"Theirs\": 0\n",
      "    },\n",
      "    \"Pronouns\": {\n",
      "        \"I\": 3,\n",
      "        \"Me\": 1,\n",
      "        \"Mine\": 0\n",
      "    },\n",
      "    \"Negative emotion\": {\n",
      "        \"Afraid\": 0,\n",
      "        \"Sad\": 0,\n",
      "        \"Hate\": 0,\n",
      "        \"Abandon\": 0,\n",
      "        \"Hurt\": 0\n",
      "    },\n",
      "    \"Negative sentiment\": {\n",
      "        \"Abominable\": 0,\n",
      "        \"Anger\": 0,\n",
      "        \"Anxious\": 0,\n",
      "        \"Bad\": 0\n",
      "    },\n",
      "    \"Positive emotion\": {\n",
      "        \"Happy\": 0,\n",
      "        \"Brave\": 0,\n",
      "        \"Love\": 0,\n",
      "        \"Nice\": 0,\n",
      "        \"Sweet\": 0\n",
      "    },\n",
      "    \"Positive sentiment\": {\n",
      "        \"Admire\": 0,\n",
      "        \"Amazing\": 0,\n",
      "        \"Assure\": 0,\n",
      "        \"Charm\": 0\n",
      "    },\n",
      "    \"Disfluencies\": {\n",
      "        \"Uh\": 0,\n",
      "        \"Um\": 0,\n",
      "        \"You know\": 0,\n",
      "        \"Er\": 0,\n",
      "        \"Ah\": 0\n",
      "    },\n",
      "    \"Self reference words\": {\n",
      "        \"I\": 3,\n",
      "        \"My\": 1,\n",
      "        \"Mine\": 0\n",
      "    },\n",
      "    \"Nominalised verbs\": {\n",
      "        \"Education\": 0,\n",
      "        \"Arrangement\": 0\n",
      "    },\n",
      "    \"sentiment\": -0.7\n",
      "}\n",
      "```\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 27\u001b[0m\n\u001b[0;32m      1\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mGiven below is a transcript enclosed in \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m brackets. \u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124m    The json below has category name as the key.\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m    For each category name you are given \u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey3\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124m    }\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     26\u001b[0m fet2 \u001b[38;5;241m=\u001b[39m get_features_2(t)\n\u001b[1;32m---> 27\u001b[0m fet2_pp \u001b[38;5;241m=\u001b[39m \u001b[43msum_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfet2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#################################\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(fet2_pp)\n",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m, in \u001b[0;36msum_values\u001b[1;34m(string)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum_values\u001b[39m(string):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart of sum_values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mstring_to_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     reduced_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, sub_dict \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m, in \u001b[0;36mstring_to_json\u001b[1;34m(sample_string)\u001b[0m\n\u001b[0;32m      4\u001b[0m sample_string \u001b[38;5;241m=\u001b[39m sample_string\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample string is \u001b[39m\u001b[38;5;124m\"\u001b[39m,sample_string)\n\u001b[1;32m----> 6\u001b[0m jl \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jl\n",
      "File \u001b[1;32m~\\.conda\\envs\\personalEnv2\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32m~\\.conda\\envs\\personalEnv2\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32m~\\.conda\\envs\\personalEnv2\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "t = \"\"\"Given below is a transcript enclosed in {} brackets. \n",
    "    The json below has category name as the key.\n",
    "    For each category name you are given \n",
    "    (a) certain words that fall into this category ('words')\n",
    "    (b) description of the category ('description')\n",
    "    \n",
    "    JSON : \n",
    "    {'Causation': {'description': 'Providing a certain level of concreteness to an explanation.', 'words': ['Because', 'Effect', 'Hence']}, 'Negation': {'description': 'Avoiding to provide a direct response.', 'words': ['No', 'Not', 'Can’t', 'Didn’t']}, 'Hedging': {'description': 'Describes words which meaning implicitly involves fuzziness.', 'words': ['May be', 'I guess', 'Sort of']}, 'Qualified assertions': {'description': 'Unveils questionable actions.', 'words': ['Needed', 'Attempted']}, 'Temporal Lacunae': {'description': 'Unexplained lapses of time.', 'words': ['Later that day', 'Afterwards']}, 'Overzealous expression': {'description': 'Expresses some level of uncertainty.', 'words': ['I swear to God', 'Honestly']}, 'Memory loss': {'description': 'Feigning memory loss.', 'words': ['I forget', 'Can’t remember']}, 'Third person plural pronouns': {'description': 'Possessive determiners to refer to things or people other than the speaker.', 'words': ['They', 'Them', 'Theirs']}, 'Pronouns': {'description': 'Possessive determiners to refer to the speaker by overemphasising their physical presence.', 'words': ['I', 'Me', 'Mine']}, 'Negative emotion': {'description': 'Negative expressions in word choice.', 'words': ['Afraid', 'Sad', 'Hate', 'Abandon', 'Hurt']}, 'Negative sentiment': {'description': 'Negative emotional effect.', 'words': ['Abominable', 'Anger', 'Anxious', 'Bad']}, 'Positive emotion': {'description': 'Positive expressions in word choice.', 'words': ['Happy', 'Brave', 'Love', 'Nice', 'Sweet']}, 'Positive sentiment': {'description': 'Positive emotional effect.', 'words': ['Admire', 'Amazing', 'Assure', 'Charm']}, 'Disfluencies': {'description': 'Interruption in the flow of speech.', 'words': ['Uh', 'Um', 'You know', 'Er', 'Ah']}, 'Self reference words': {'description': 'Deceivers tend to use fewer self-referencing expressions.', 'words': ['I', 'My', 'Mine']}, 'Nominalised verbs': {'description': 'Nouns derived from verbs. Nominalisations tend to hide the real action.', 'words': ['Education', 'Arrangement']}}\n",
    "    \n",
    "    1) For each category provide a dictionary of words along with its frequency of occurance in the transcript\n",
    "    2) calculate the overall sentiment of the transcript on a scale of -1 to +1 where -1 is extremely negative and +1 is extremely postive\n",
    "    \n",
    "    Give your response as json with keys as category name (as given in data) and 'sentiment'\n",
    "    \n",
    "    Transcript : { There is a criminal case that is listed under your name for tax fraud and tax evasion and there is also a warrant out for your arrest now. There's a warrant out for my arrest. This is a recordable line sir. I have to play this recording in the court also. We don't need any interruption in this court. Sorry this is going to get played in court. Yeah the recording is going to be in court.}\n",
    "    \n",
    "    Please Note it is very important that your response should be a valid json object directly readable using \n",
    "    json.loads()\n",
    "    Example response \n",
    "    {\n",
    "    'key1':'value1',\n",
    "    'key2':'value2',\n",
    "    'key3':'value3'\n",
    "    }\"\"\"\n",
    "\n",
    "fet2 = get_features_2(t)\n",
    "fet2_pp = sum_values(fet2)\n",
    "print(\"#################################\")\n",
    "print(fet2_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f732fbbb-7522-444c-a734-77f423fa6a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "mystr = \"\"\"     [   {   1:'hello'   ,   'y':4,      \"you\"   :\"have\"}, {1:'hello'}]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86c71399-0d06-401d-aea9-fc334a5f9d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "mystr = mystr.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9387d545-94bc-4102-bcba-5516d8c7957a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[   {   1:\\'hello\\'   ,   \\'y\\':4,      \"you\"   :\"have\"}, {1:\\'hello\\'}]'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6e6713-078a-4c33-938c-ccebe0980192",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if mystr[0]==\"[\" and mystr[-1]==\"]\":\n",
    "    \n",
    "else:\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ae41d2-765e-4e14-a5c0-bc41355394bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mystr.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05ab9b7-408c-4f9d-9519-b72e47abf70e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e20e68-6b05-4a4e-8fd8-bcfb38202eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed3cb5b-856c-4c71-bf65-d4da428f6b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping playback and checkpoint handler...\n",
      "Stopping playback and checkpoint handler...\n",
      "Stopping playback and checkpoint handler...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sample_string = '''\n",
    "{\n",
    "    \"Causation\": {\n",
    "        \"Because\": 0,\n",
    "        \"Effect\": 1,\n",
    "        \"Hence\": 1\n",
    "    },\n",
    "    \"Negation\": {\n",
    "        \"No\": 0,\n",
    "        \"Not\": 3,\n",
    "        \"Can’t\": 2,\n",
    "        \"Didn’t\": 0\n",
    "    },\n",
    "    \"Hedging\": {\n",
    "        \"May be\": 0,\n",
    "        \"I guess\": 0,\n",
    "        \"Sort of\": 0\n",
    "    },\n",
    "    \"Qualified assertions\": {\n",
    "        \"Needed\": 0,\n",
    "        \"Attempted\": 0\n",
    "    },\n",
    "    \"Temporal Lacunae\": {\n",
    "        \"Later that day\": 0,\n",
    "        \"Afterwards\": 0\n",
    "    },\n",
    "    \"Overzealous expression\": {\n",
    "        \"I swear to God\": 0,\n",
    "        \"Honestly\": 0\n",
    "    },\n",
    "    \"Memory loss\": {\n",
    "        \"I forget\": 0,\n",
    "        \"Can’t remember\": 0\n",
    "    },\n",
    "    \"Third person plural pronouns\": {\n",
    "        \"They\": 0,\n",
    "        \"Them\": 0,\n",
    "        \"Theirs\": 0\n",
    "    },\n",
    "    \"Pronouns\": {\n",
    "        \"I\": 0,\n",
    "        \"Me\": 0,\n",
    "        \"Mine\": 0\n",
    "    },\n",
    "    \"Negative emotion\": {\n",
    "        \"Afraid\": 0,\n",
    "        \"Sad\": 0,\n",
    "        \"Hate\": 0,\n",
    "        \"Abandon\": 0,\n",
    "        \"Hurt\": 0\n",
    "    },\n",
    "    \"Negative sentiment\": {\n",
    "        \"Abominable\": 0,\n",
    "        \"Anger\": 0,\n",
    "        \"Anxious\": 0,\n",
    "        \"Bad\": 0\n",
    "    },\n",
    "    \"Positive emotion\": {\n",
    "        \"Happy\": 0,\n",
    "        \"Brave\": 0,\n",
    "        \"Love\": 0,\n",
    "        \"Nice\": 0,\n",
    "        \"Sweet\": 0\n",
    "    },\n",
    "    \"Positive sentiment\": {\n",
    "        \"Admire\": 0,\n",
    "        \"Amazing\": 0,\n",
    "        \"Assure\": 0,\n",
    "        \"Charm\": 0\n",
    "    },\n",
    "    \"Disfluencies\": {\n",
    "        \"Uh\": 0,\n",
    "        \"Um\": 0,\n",
    "        \"You know\": 0,\n",
    "        \"Er\": 0,\n",
    "        \"Ah\": 0\n",
    "    },\n",
    "    \"Self reference words\": {\n",
    "        \"I\": 0,\n",
    "        \"My\": 0,\n",
    "        \"Mine\": 0\n",
    "    },\n",
    "    \"Nominalised verbs\": {\n",
    "        \"Education\": 0,\n",
    "        \"Arrangement\": 0\n",
    "    },\n",
    "    \"sentiment\": -0.8\n",
    "}\n",
    "'''\n",
    "\n",
    "json_data = string_to_json(sample_string)\n",
    "reduced_dict = sum_values(json_data)\n",
    "print(reduced_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12728501-c337-41e9-8417-33960a5459f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3969067d-95d2-48ab-8667-27577f77766a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43953082-17d0-4b9a-8c21-2cba51e89bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19de2e34-d9fd-4996-bbca-d8008bb68ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "def download_youtube_audio(url):\n",
    "    print(url)\n",
    "    # Create a YouTube object\n",
    "    yt = YouTube(url)\n",
    "    \n",
    "    # Extract the highest quality audio stream available\n",
    "    audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "    \n",
    "    # Get the video title and sanitize it for use as a filename\n",
    "    video_title = yt.title\n",
    "    safe_title = \"\".join([c if c.isalnum() or c in (' ', '.', '_') else '_' for c in video_title])\n",
    "    output_path = f\"{safe_title}.wav\"\n",
    "    print(\"h1\")\n",
    "    # Download the audio stream\n",
    "    audio_file_path = audio_stream.download(filename=\"temp_audio\")\n",
    "    \n",
    "    # Convert the downloaded audio to .wav format using pydub\n",
    "    audio = AudioSegment.from_file(audio_file_path)\n",
    "    audio.export(output_path, format=\"wav\")\n",
    "    print(\"h2\")\n",
    "    # Remove the temporary audio file\n",
    "    os.remove(audio_file_path)\n",
    "\n",
    "    print(f\"Audio downloaded and saved as {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "vs = ['https://www.youtube.com/watch?v=q_qdC6grfIA', 'https://www.youtube.com/watch?v=n4iN8fras1Y']\n",
    "for video_url in vs:\n",
    "   pass\n",
    "    # download_youtube_audio(video_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bd4e83-fa7b-42f7-bbe6-5c095fb07138",
   "metadata": {},
   "source": [
    "## Extract audio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6765624-fd90-42bd-a5fb-291a7f84317d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a198b042-e1d0-47d9-8e70-23fc8fec366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jupyter --config-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5804bef-04cb-4f82-a180-c7b9258b44f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13b3f4e-d920-4c79-b3b4-9b390bf5e1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d425012-e3dc-49fe-bf3c-d9d3764d783d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "290fc2f1-4d15-4290-b023-adde2a30a8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0ceeff4-62f7-4eeb-bd6c-e1a74a954851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c21f7972-cd6b-4d21-bda3-78373946a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = None\n",
    "\n",
    "def g():\n",
    "    global start_time\n",
    "    \n",
    "    if start_time is None:\n",
    "        # Record the start time\n",
    "        start_time = time.time()\n",
    "        #print(\"Timer started.\")\n",
    "    else:\n",
    "        # Calculate the time interval\n",
    "        end_time = time.time()\n",
    "        interval = (end_time - start_time) / 60  # Convert to minutes\n",
    "        print(f\"Time interval: {interval:.2f} minutes\")\n",
    "        # Reset the start time\n",
    "        start_time = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f32742ee-6a88-4360-b9f1-84305b4246a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Stopping playback and checkpoint handler...\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Stopping playback and checkpoint handler...\n",
      "Stopping playback and checkpoint handler...\n",
      "Stopping playback and checkpoint handler...\n",
      "Stopping playback and checkpoint handler...\n",
      "Stopping playback and checkpoint handler...\n",
      "Stopping playback and checkpoint handler...\n",
      "Stopping playback and checkpoint handler...\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07ca9bbb-9a24-41c5-9502-7f02eb52dcbc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n",
      "Dummy function called!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58226c86-fc72-49c3-b240-0e499619ff1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-Crossing Rate (ZCR): High ZCR indicates more frequent sign changes in the signal, capturing noisiness and abrupt changes in speech, which can signal stress or nervousness.\n",
      "Time interval: 0.01 minutes\n",
      "Root Mean Square Energy (RMSE): Measures the loudness of speech. Sudden changes or high energy can indicate emotional stress or intentional emphasis.\n",
      "Time interval: 0.02 minutes\n",
      "Spectral Centroid: Captures the center of mass of the spectrum, indicating the 'brightness' of the sound. Deviations from normal patterns can indicate emotional stress or emphasis.\n",
      "Time interval: 0.03 minutes\n",
      "Spectral Bandwidth: Measures the range of frequencies. Wider bandwidth can indicate stressed speech or background noise.\n",
      "Time interval: 0.04 minutes\n",
      "Spectral Roll-off: Helps to identify voiced vs. unvoiced sounds. Higher roll-off can indicate abrupt changes in speech patterns.\n",
      "Time interval: 0.03 minutes\n",
      "Pitch: Variations in pitch can indicate emotional stress or intentional modulation used in deception.\n",
      "Time interval: 0.04 minutes\n",
      "Prosodic Features (e.g., intonation): Includes intonation, stress, and rhythm. Irregularities in these features can indicate emotional stress or rehearsed speech.\n",
      "Time interval: 0.00 minutes\n",
      "Speaking Rate: The rate of speech. Unnaturally fast or slow speaking rates can indicate nervousness or rehearsed speech.\n",
      "Time interval: 0.02 minutes\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "708e1355-c4f2-4d32-956e-1fbeca0d2da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'zcr': 0.044475452999882245,\n",
       " 'rmse': 0.22577345,\n",
       " 'spectral_centroid': 1791.1599853658656,\n",
       " 'spectral_bandwidth': 1993.0626842945642,\n",
       " 'spectral_rolloff': 3088.9584122288893,\n",
       " 'pitch': 737.019,\n",
       " 'intonation': 1081.7798,\n",
       " 'speaking_rate': 1.3315324303057554}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947cb230-0aa6-42cd-9fe9-4fc12286c6c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f38e0318-f6b9-4016-ae3e-651659c5949c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# 7. Mel-Frequency Cepstral Coefficients (MFCCs)\\nmfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13).T, axis=0)\\nprint(\"Mel-Frequency Cepstral Coefficients (MFCCs): Capture the power spectrum of the speech signal and can highlight deviations in vocal tract characteristics, indicating stress or deception.\")\\nprint(mfccs)'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# 7. Mel-Frequency Cepstral Coefficients (MFCCs)\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13).T, axis=0)\n",
    "print(\"Mel-Frequency Cepstral Coefficients (MFCCs): Capture the power spectrum of the speech signal and can highlight deviations in vocal tract characteristics, indicating stress or deception.\")\n",
    "print(mfccs)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d36c00ac-6a69-43df-9d2d-f67146a30977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# 8. Chroma Feature\\nchroma_stft = np.mean(librosa.feature.chroma_stft(y=y, sr=sr).T, axis=0)\\nprint(\"Chroma Feature: Represents harmonic content. Anomalous chroma patterns can indicate stress or unnatural speech modulation.\")\\nprint(chroma_stft)'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# 8. Chroma Feature\n",
    "chroma_stft = np.mean(librosa.feature.chroma_stft(y=y, sr=sr).T, axis=0)\n",
    "print(\"Chroma Feature: Represents harmonic content. Anomalous chroma patterns can indicate stress or unnatural speech modulation.\")\n",
    "print(chroma_stft)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de1744ff-e210-452b-813f-bc4559194d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# 10. Formant Frequencies (Approximated using LPC)\\nlpc_coeffs = librosa.lpc(y, order=2)\\nformants = np.roots(lpc_coeffs)\\nformants = [np.abs(f) for f in formants if np.imag(f) == 0]\\nformants = np.mean(formants) if formants else 0\\nprint(\"Formant Frequencies: Formants are resonant frequencies of the vocal tract. Unusual formant patterns can indicate stress or intentional voice alteration.\")\\nprint(formants)'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# 10. Formant Frequencies (Approximated using LPC)\n",
    "lpc_coeffs = librosa.lpc(y, order=2)\n",
    "formants = np.roots(lpc_coeffs)\n",
    "formants = [np.abs(f) for f in formants if np.imag(f) == 0]\n",
    "formants = np.mean(formants) if formants else 0\n",
    "print(\"Formant Frequencies: Formants are resonant frequencies of the vocal tract. Unusual formant patterns can indicate stress or intentional voice alteration.\")\n",
    "print(formants)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38478137-ce19-403b-8814-92005bcd1b22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # 12. Voice Activity Detection (VAD)\\nintervals = librosa.effects.split(y, top_db=20)\\nvad = len(intervals) / len(y)\\nprint(\"Voice Activity Detection (VAD): Identifies segments of speech vs. silence. Unusual patterns can indicate scripted or unnatural speech.\")\\nprint(intervals[0:10])'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # 12. Voice Activity Detection (VAD)\n",
    "intervals = librosa.effects.split(y, top_db=20)\n",
    "vad = len(intervals) / len(y)\n",
    "print(\"Voice Activity Detection (VAD): Identifies segments of speech vs. silence. Unusual patterns can indicate scripted or unnatural speech.\")\n",
    "print(intervals[0:10])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbbb90f-3c19-430b-8a14-db263ccbe6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3d7539b-6d1c-421c-99a3-4fc31d8828c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9bbe2cd1-c3b3-47f5-9f56-ece8449666d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given below is a transcript enclosed in {} brackets. \n",
      "The json below has category name as the key.\n",
      "For each category name you are given \n",
      "(a) certain words that fall into this category ('words')\n",
      "(b) description of the category ('description')\n",
      "\n",
      "JSON : \n",
      "{'Causation': {'description': 'Providing a certain level of concreteness to an explanation.', 'words': ['Because', 'Effect', 'Hence']}, 'Negation': {'description': 'Avoiding to provide a direct response.', 'words': ['No', 'Not', 'Can’t', 'Didn’t']}, 'Hedging': {'description': 'Describes words which meaning implicitly involves fuzziness.', 'words': ['May be', 'I guess', 'Sort of']}, 'Qualified assertions': {'description': 'Unveils questionable actions.', 'words': ['Needed', 'Attempted']}, 'Temporal Lacunae': {'description': 'Unexplained lapses of time.', 'words': ['Later that day', 'Afterwards']}, 'Overzealous expression': {'description': 'Expresses some level of uncertainty.', 'words': ['I swear to God', 'Honestly']}, 'Memory loss': {'description': 'Feigning memory loss.', 'words': ['I forget', 'Can’t remember']}, 'Third person plural pronouns': {'description': 'Possessive determiners to refer to things or people other than the speaker.', 'words': ['They', 'Them', 'Theirs']}, 'Pronouns': {'description': 'Possessive determiners to refer to the speaker by overemphasising their physical presence.', 'words': ['I', 'Me', 'Mine']}, 'Negative emotion': {'description': 'Negative expressions in word choice.', 'words': ['Afraid', 'Sad', 'Hate', 'Abandon', 'Hurt']}, 'Negative sentiment': {'description': 'Negative emotional effect.', 'words': ['Abominable', 'Anger', 'Anxious', 'Bad']}, 'Positive emotion': {'description': 'Positive expressions in word choice.', 'words': ['Happy', 'Brave', 'Love', 'Nice', 'Sweet']}, 'Positive sentiment': {'description': 'Positive emotional effect.', 'words': ['Admire', 'Amazing', 'Assure', 'Charm']}, 'Disfluencies': {'description': 'Interruption in the flow of speech.', 'words': ['Uh', 'Um', 'You know', 'Er', 'Ah']}, 'Self reference words': {'description': 'Deceivers tend to use fewer self-referencing expressions.', 'words': ['I', 'My', 'Mine']}, 'Nominalised verbs': {'description': 'Nouns derived from verbs. Nominalisations tend to hide the real action.', 'words': ['Education', 'Arrangement']}}\n",
      "\n",
      "1) For each category provide a dictionary of words along with its frequency of occurance in the transcript\n",
      "2) calculate the overall sentiment of the transcript on a scale of -1 to +1 where -1 is extremely negative and +1 is extremely postive\n",
      "\n",
      "Give your response as json with keys as category name (as given in data) and 'sentiment'\n",
      "\n",
      "Transcript : { There is a criminal case that is listed under your name for tax fraud and tax evasion and there is also a warrant out for your arrest now. There's a warrant out for my arrest. This is a recordable line sir. I have to play this recording in the court house so we don't need any interruption in this call. Sorry this is going to get played in court. Yeah the recording is going to be played in the court house. We found out a miscalculation of 1693 pounds outstanding under your name. So at this point of time we have only two options. The first option is to go to court and fight the case. In case if you're found guilty you have to pay a penalty fine of 19,000 pounds and a reasonable of two years and if you want to resolve the matter outside of the court house then you have to pay the outstanding amount which is 1693 pounds to the government. If it's fine it was not your intention to deport the HMRC then this whole money is going to be defunded back to you. Whether you want to do you want to go to court or you want to pay and resolve the matter. I have no idea mate. Sorry this is all just sort of caught me a little bit. I wasn't expecting this at all. Do I have to decide now? Sir over the recordable line because I have to submit this recording to the court house and laws not according to you have to go over the law. So you have to come from the department what do you want to do. If you want to go to court you can simply hang up the call and wait for police they will come to you and they will take you in custody. Sorry sorry who sorry who. They will come and take you in custody. Oh the police the police sorry I couldn't understand you sorry right okay. Oh my god sorry so if I go to court I have to pay. If you if you if you phone guilty you have to pay the outstanding amount and the penalty fine of 19000 pounds and if you want to resolve the matter. Yes you just need to pay 1693 pounds to the government. Oh god how do I do that. So you have to do it online by yourself. We can only give you the transaction code of the court house so you can pay directly to the court house. Do you have this funds available to resolve the matter? Well look I yeah I mean I can't have the police come around. Which bank you're banking with sir? HSBC. Apart from HSBC you do have any other bank account like Revolut, Monzo, Monis or any other bank? No I think most of my stuff is with HSBC. So please confirm your sort court sir so we can generate the transaction code from our side and we will give it to you. Right okay and sorry who are you calling from but are you calling from HMRC or the police sorry? I am I am calling from HMRC right called London. In sorry where? Oh in London. Yeah. Whereabouts in London? HMRC inner court London. In a court? Yeah. Right right okay. And is I mean have you sorry mate because obviously I see that you've just called me is there any way like if you've got any ID or anything that you could show me or is there a website I can check out or something? Sir I can verify this call so you don't need to be worried about that if you want to check that is that real or not so please check the phone is there any call coming to you? There is actually yeah someone trying to get through now. Yeah please pick up the line please please pick up the line sir that's my official number. Okay hold on. Hello this is Daniel. Yeah this side same officer so please open google.com and I will show you whom you're talking to. So hang on so you've just called me on a different number that hang on this is. Yeah okay. That's me that's my official number please open google.com sir just click on that sir. Yeah. Now you are on the official website of government so please scroll down the page below is there any phone number of inquiries. That's exactly the same number that you're calling me on. So that's my official number so now you can tell me whatever you want to do. Oh I will definitely pay that 1600 pounds please mate because you're calling from HMRC in a Crown Court in a London Crown Court yeah okay I see now. So you have to confirm your sort code first so we can generate a foundation code and give it to you. Yeah yeah mate there's absolutely no way I'm going to give you my sort code because you're a criminal you're a crook and you prey on victims and it's outrageous what you do you prey on vulnerable people you steal their money and you use it probably for organized crime you're not calling from HMRC you're not calling from London this isn't the number you've spoofed it I know how you criminals work you're the person who should be arrested goodbye.}\n",
      "\n",
      "Please Note it is very important that your response should be a valid json object directly readable using \n",
      "json.loads()\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "33da9308-8b58-4b1d-994f-4035a965ba20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1dc066-7d1a-45a9-b5b1-8e6364432a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ba310b7d-d594-4608-827a-f46b2bbf61aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"Causation\": {\n",
      "    \"words\": {\n",
      "      \"Because\": 1,\n",
      "      \"Effect\": 0,\n",
      "      \"Hence\": 0\n",
      "    }\n",
      "  },\n",
      "  \"Negation\": {\n",
      "    \"words\": {\n",
      "      \"No\": 3,\n",
      "      \"Not\": 4,\n",
      "      \"Can’t\": 1,\n",
      "      \"Didn’t\": 0\n",
      "    }\n",
      "  },\n",
      "  \"Hedging\": {\n",
      "    \"words\": {\n",
      "      \"May be\": 0,\n",
      "      \"I guess\": 0,\n",
      "      \"Sort of\": 1\n",
      "    }\n",
      "  },\n",
      "  \"Qualified assertions\": {\n",
      "    \"words\": {\n",
      "      \"Needed\": 0,\n",
      "      \"Attempted\": 0\n",
      "    }\n",
      "  },\n",
      "  \"Temporal Lacunae\": {\n",
      "    \"words\": {\n",
      "      \"Later that day\": 0,\n",
      "      \"Afterwards\": 0\n",
      "    }\n",
      "  },\n",
      "  \"Overzealous expression\": {\n",
      "    \"words\": {\n",
      "      \"I swear to God\": 0,\n",
      "      \"Honestly\": 0\n",
      "    }\n",
      "  },\n",
      "  \"Memory loss\": {\n",
      "    \"words\": {\n",
      "      \"I forget\": 0,\n",
      "      \"Can’t remember\": 0\n",
      "    }\n",
      "  },\n",
      "  \"Third person plural pronouns\": {\n",
      "    \"words\": {\n",
      "      \"They\": 3,\n",
      "      \"Them\": 0,\n",
      "      \"Theirs\": 0\n",
      "    }\n",
      "  },\n",
      "  \"Pronouns\": {\n",
      "    \"words\": {\n",
      "      \"I\": 13,\n",
      "      \"Me\": 2,\n",
      "      \"Mine\": 0\n",
      "    }\n",
      "  },\n",
      "  \"Negative emotion\": {\n",
      "    \"words\": {\n",
      "      \"Afraid\": 0,\n",
      "      \"Sad\": 0,\n",
      "      \"Hate\": 0,\n",
      "      \"Abandon\": 0,\n",
      "      \"Hurt\": 0\n",
      "    }\n",
      "  },\n",
      "  \"Negative sentiment\": {\n",
      "    \"words\": {\n",
      "      \"Abominable\": 0,\n",
      "      \"Anger\": 0,\n",
      "      \"Anxious\": 0,\n",
      "      \"Bad\": 1\n",
      "    }\n",
      "  },\n",
      "  \"Positive emotion\": {\n",
      "    \"words\": {\n",
      "      \"Happy\": 0,\n",
      "      \"Brave\": 0,\n",
      "      \"Love\": 0,\n",
      "      \"Nice\": 0,\n",
      "      \"Sweet\": 0\n",
      "    }\n",
      "  },\n",
      "  \"Positive sentiment\": {\n",
      "    \"words\": {\n",
      "      \"Admire\": 0,\n",
      "      \"Amazing\": 0,\n",
      "      \"Assure\": 1,\n",
      "      \"Charm\": 0\n",
      "    }\n",
      "  },\n",
      "  \"Disfluencies\": {\n",
      "    \"words\": {\n",
      "      \"Uh\": 0,\n",
      "      \"Um\": 0,\n",
      "      \"You know\": 0,\n",
      "      \"Er\": 0,\n",
      "      \"Ah\": 0\n",
      "    }\n",
      "  },\n",
      "  \"Self reference words\": {\n",
      "    \"words\": {\n",
      "      \"I\": 13,\n",
      "      \"My\": 5,\n",
      "      \"Mine\": 0\n",
      "    }\n",
      "  },\n",
      "  \"Nominalised verbs\": {\n",
      "    \"words\": {\n",
      "      \"Education\": 0,\n",
      "      \"Arrangement\": 0\n",
      "    }\n",
      "  },\n",
      "  \"sentiment\": -0.8\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7277eadb-0695-48e4-ab3f-6bbb893c1ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33ff32f-bfce-4682-ab99-d7a4e129ddb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa29957-9ee5-4323-add3-77588559c60c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2e2fcf-1317-443a-b87e-bdfa9cc53a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "583e9952-04d8-4926-887d-2098e6a09d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Causation': {'description': 'Providing a certain level of concreteness to an explanation.',\n",
       "  'words': ['Because', 'Effect', 'Hence']},\n",
       " 'Negation': {'description': 'Avoiding to provide a direct response.',\n",
       "  'words': ['No', 'Not', 'Can’t', 'Didn’t']},\n",
       " 'Hedging': {'description': 'Describes words which meaning implicitly involves fuzziness.',\n",
       "  'words': ['May be', 'I guess', 'Sort of']},\n",
       " 'Qualified assertions': {'description': 'Unveils questionable actions.',\n",
       "  'words': ['Needed', 'Attempted']},\n",
       " 'Temporal Lacunae': {'description': 'Unexplained lapses of time.',\n",
       "  'words': ['Later that day', 'Afterwards']},\n",
       " 'Overzealous expression': {'description': 'Expresses some level of uncertainty.',\n",
       "  'words': ['I swear to God', 'Honestly']},\n",
       " 'Memory loss': {'description': 'Feigning memory loss.',\n",
       "  'words': ['I forget', 'Can’t remember']},\n",
       " 'Third person plural pronouns': {'description': 'Possessive determiners to refer to things or people other than the speaker.',\n",
       "  'words': ['They', 'Them', 'Theirs']},\n",
       " 'Pronouns': {'description': 'Possessive determiners to refer to the speaker by overemphasising their physical presence.',\n",
       "  'words': ['I', 'Me', 'Mine']},\n",
       " 'Negative emotion': {'description': 'Negative expressions in word choice.',\n",
       "  'words': ['Afraid', 'Sad', 'Hate', 'Abandon', 'Hurt']},\n",
       " 'Negative sentiment': {'description': 'Negative emotional effect.',\n",
       "  'words': ['Abominable', 'Anger', 'Anxious', 'Bad']},\n",
       " 'Positive emotion': {'description': 'Positive expressions in word choice.',\n",
       "  'words': ['Happy', 'Brave', 'Love', 'Nice', 'Sweet']},\n",
       " 'Positive sentiment': {'description': 'Positive emotional effect.',\n",
       "  'words': ['Admire', 'Amazing', 'Assure', 'Charm']},\n",
       " 'Disfluencies': {'description': 'Interruption in the flow of speech.',\n",
       "  'words': ['Uh', 'Um', 'You know', 'Er', 'Ah']},\n",
       " 'Self reference words': {'description': 'Deceivers tend to use fewer self-referencing expressions.',\n",
       "  'words': ['I', 'My', 'Mine']},\n",
       " 'Nominalised verbs': {'description': 'Nouns derived from verbs. Nominalisations tend to hide the real action.',\n",
       "  'words': ['Education', 'Arrangement']}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linguistic_markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e2905c00-8b8a-49a4-87f6-41e0ccc6722c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a customer care professional, I want to analyze this audio transcript to detect any\n",
      "             anomalies or potential fraud. Please identify and highlight instances of the following markers,\n",
      "             and provide a summary of the context in which they are used. Also please indicate if this is a potential\n",
      "             fraud with a confidence score: Causation: Keywords indicating cause-and-effect relationships, providing a certain level of\n",
      "             concreteness to an explanation. Examples: 'Because,' 'Effect,' 'Hence.' Negation: Words or phrases\n",
      "             avoiding a direct response. Examples: 'No, ' 'Not,' 'Canâ€™t,' 'Didnâ€™t.' Hedging: Words that implicitly\n",
      "             involve fuzziness. Examples: 'May be, ' 'I guess,' 'Sort of.' Qualified Assertions: Phrases that unveil\n",
      "             questionable actions. Examples: 'Needed,' 'Attempted.' Temporal Lacunae: Unexplained lapses of time.\n",
      "             Examples: 'Later that day, ' 'Afterwards.' Overzealous Expression: Phrases expressing some level of\n",
      "             uncertainty. Examples: 'I swear to God,' 'Honestly.' Memory Loss: Phrases feigning memory loss.\n",
      "             Examples: 'I forget,' 'Canâ€™t remember.' Third Person Plural Pronouns: Use of pronouns to refer to\n",
      "             others. Examples: 'They,' 'Them,' 'Theirs.' Self-Reference Words: Pronouns referring to the speaker,\n",
      "             often emphasizing their physical presence. Examples: 'I,' 'Me,' 'Mine.' Negative Emotion: Words with\n",
      "             negative connotations. Examples: 'Afraid, ' 'Sad,' 'Hate,' 'Abandon,' 'Hurt.' Negative Sentiment: Words\n",
      "             indicating negative emotional effects. Examples: 'Abominable,' 'Anger,' 'Anxious,' 'Bad.' Positive\n",
      "             Emotion: Words with positive connotations. Examples: 'Happy,' 'Brave,' 'Love,' 'Nice,' 'Sweet.' Positive\n",
      "             Sentiment: Words indicating positive emotional effects. Examples: 'Admire,' 'Amazing,' 'Assure,\n",
      "             ' 'Charm.' Disfluencies: Interruptions in the flow of speech. Examples: 'Uh,' 'Um,' 'You know,' 'Er,\n",
      "             ' 'Ah.' Nominalized Verbs: Nouns derived from verbs, often hiding the real action. Examples: 'Education,\n",
      "             ' 'Arrangement.'\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"As a customer care professional, I want to analyze this audio transcript to detect any\n",
    "             anomalies or potential fraud. Please identify and highlight instances of the following markers,\n",
    "             and provide a summary of the context in which they are used. Also please indicate if this is a potential\n",
    "             fraud with a confidence score: Causation: Keywords indicating cause-and-effect relationships, providing a certain level of\n",
    "             concreteness to an explanation. Examples: 'Because,' 'Effect,' 'Hence.' Negation: Words or phrases\n",
    "             avoiding a direct response. Examples: 'No, ' 'Not,' 'Canâ€™t,' 'Didnâ€™t.' Hedging: Words that implicitly\n",
    "             involve fuzziness. Examples: 'May be, ' 'I guess,' 'Sort of.' Qualified Assertions: Phrases that unveil\n",
    "             questionable actions. Examples: 'Needed,' 'Attempted.' Temporal Lacunae: Unexplained lapses of time.\n",
    "             Examples: 'Later that day, ' 'Afterwards.' Overzealous Expression: Phrases expressing some level of\n",
    "             uncertainty. Examples: 'I swear to God,' 'Honestly.' Memory Loss: Phrases feigning memory loss.\n",
    "             Examples: 'I forget,' 'Canâ€™t remember.' Third Person Plural Pronouns: Use of pronouns to refer to\n",
    "             others. Examples: 'They,' 'Them,' 'Theirs.' Self-Reference Words: Pronouns referring to the speaker,\n",
    "             often emphasizing their physical presence. Examples: 'I,' 'Me,' 'Mine.' Negative Emotion: Words with\n",
    "             negative connotations. Examples: 'Afraid, ' 'Sad,' 'Hate,' 'Abandon,' 'Hurt.' Negative Sentiment: Words\n",
    "             indicating negative emotional effects. Examples: 'Abominable,' 'Anger,' 'Anxious,' 'Bad.' Positive\n",
    "             Emotion: Words with positive connotations. Examples: 'Happy,' 'Brave,' 'Love,' 'Nice,' 'Sweet.' Positive\n",
    "             Sentiment: Words indicating positive emotional effects. Examples: 'Admire,' 'Amazing,' 'Assure,\n",
    "             ' 'Charm.' Disfluencies: Interruptions in the flow of speech. Examples: 'Uh,' 'Um,' 'You know,' 'Er,\n",
    "             ' 'Ah.' Nominalized Verbs: Nouns derived from verbs, often hiding the real action. Examples: 'Education,\n",
    "             ' 'Arrangement.'\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a65c9c7-d28e-47f0-9217-d09a6c757e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601e286b-3ffc-4f2a-9083-5042496cd2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47836260-1615-4977-9812-7df309cad3f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ad70a1-9775-41e8-9fb3-c85934debbe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b4fcab-c272-493c-8139-79a7181d9e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068a176b-b6a6-4a29-81c7-506e5ed8ca6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19088eb-b2fa-4d68-8be0-0ea238c65b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a2ca8a-5cbc-451c-a2a2-1e3406fc0024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36078eff-2c52-476b-bbb0-7b8e6ab1864c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6456fa-983e-4b17-92d2-37bacda48894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87c9542a-b879-4419-ae8a-5ffd60b20607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a27d0978-4105-45f2-88fc-a03309abb762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e2000d9-1d49-4df0-945d-d23ffed35ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "463d3aef-ca27-428c-84c4-92c2aaad34b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e195425c-3272-4404-bbde-d7dedf9c109c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There is a criminal case that is listed under your name for tax fraud and tax evasion and there is also a warrant out for your arrest now. There's a warrant out for my arrest. This is a recordable line sir. I have to play this recording in the court house so we don't need any interruption in this call. Sorry this is going to get played in court. Yeah the recording is going to be played in the court house. We found out a miscalculation of 1693 pounds outstanding under your name. So at this point of time we have only two options. The first option is to go to court and fight the case. In case if you're found guilty you have to pay a penalty fine of 19,000 pounds and a reasonable of two years and if you want to resolve the matter outside of the court house then you have to pay the outstanding amount which is 1693 pounds to the government. If it's fine it was not your intention to deport the HMRC then this whole money is going to be defunded back to you. Whether you want to do you want to go to court or you want to pay and resolve the matter. I have no idea mate. Sorry this is all just sort of caught me a little bit. I wasn't expecting this at all. Do I have to decide now? Sir over the recordable line because I have to submit this recording to the court house and laws not according to you have to go over the law. So you have to come from the department what do you want to do. If you want to go to court you can simply hang up the call and wait for police they will come to you and they will take you in custody. Sorry sorry who sorry who. They will come and take you in custody. Oh the police the police sorry I couldn't understand you sorry right okay. Oh my god sorry so if I go to court I have to pay. If you if you if you phone guilty you have to pay the outstanding amount and the penalty fine of 19000 pounds and if you want to resolve the matter. Yes you just need to pay 1693 pounds to the government. Oh god how do I do that. So you have to do it online by yourself. We can only give you the transaction code of the court house so you can pay directly to the court house. Do you have this funds available to resolve the matter? Well look I yeah I mean I can't have the police come around. Which bank you're banking with sir? HSBC. Apart from HSBC you do have any other bank account like Revolut, Monzo, Monis or any other bank? No I think most of my stuff is with HSBC. So please confirm your sort court sir so we can generate the transaction code from our side and we will give it to you. Right okay and sorry who are you calling from but are you calling from HMRC or the police sorry? I am I am calling from HMRC right called London. In sorry where? Oh in London. Yeah. Whereabouts in London? HMRC inner court London. In a court? Yeah. Right right okay. And is I mean have you sorry mate because obviously I see that you've just called me is there any way like if you've got any ID or anything that you could show me or is there a website I can check out or something? Sir I can verify this call so you don't need to be worried about that if you want to check that is that real or not so please check the phone is there any call coming to you? There is actually yeah someone trying to get through now. Yeah please pick up the line please please pick up the line sir that's my official number. Okay hold on. Hello this is Daniel. Yeah this side same officer so please open google.com and I will show you whom you're talking to. So hang on so you've just called me on a different number that hang on this is. Yeah okay. That's me that's my official number please open google.com sir just click on that sir. Yeah. Now you are on the official website of government so please scroll down the page below is there any phone number of inquiries. That's exactly the same number that you're calling me on. So that's my official number so now you can tell me whatever you want to do. Oh I will definitely pay that 1600 pounds please mate because you're calling from HMRC in a Crown Court in a London Crown Court yeah okay I see now. So you have to confirm your sort code first so we can generate a foundation code and give it to you. Yeah yeah mate there's absolutely no way I'm going to give you my sort code because you're a criminal you're a crook and you prey on victims and it's outrageous what you do you prey on vulnerable people you steal their money and you use it probably for organized crime you're not calling from HMRC you're not calling from London this isn't the number you've spoofed it I know how you criminals work you're the person who should be arrested goodbye.\n"
     ]
    }
   ],
   "source": [
    "# Print the transcription result\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "639e54d7-df09-4229-9e19-b392e01e3398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4237d65f-4b16-46e2-8b78-4c7ad23e8e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afadbe04-72fd-40d2-9e48-f34b823b690e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0536ecb4-0c52-4c17-a7ee-edb4c10bc673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb45007e-015e-4eaf-94e9-741ab2ffbf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markers detected:\n",
      "\n",
      "Causation: 'If,' 'Because'\n",
      "Negation: 'No,' 'Not'\n",
      "Hedging: 'Sort of'\n",
      "Qualified Assertions: 'Need'\n",
      "Temporal Lacunae: None\n",
      "Overzealous Expression: None\n",
      "Memory Loss: None\n",
      "Third Person Plural Pronouns: 'They'\n",
      "Self-Reference Words: 'I,' 'Me,' 'My'\n",
      "Negative Emotion: 'Afraid'\n",
      "Negative Sentiment: 'Criminal,' 'Fraud,' 'Evasion,' 'Arrest,' 'Guilty,' 'Penalty,' 'Warrant'\n",
      "Positive Emotion: None\n",
      "Positive Sentiment: None\n",
      "Disfluencies: 'Uh,' 'Um'\n",
      "Nominalized Verbs: 'Interruption,' 'Recording,' 'Court,' 'House'\n",
      "\n",
      "Summary:\n",
      "An unidentified individual purporting to be a representative of HMRC (Her Majesty's Revenue and Customs) informs the speaker that he is implicated in tax fraud and evasion, and that there is an arrest warrant. The individual presents the speaker with two options: go to court or pay the outstanding amount (1693 pounds) directly to the government. Initially flustered and confused, the speaker asks for more details, clarification, and evidence of the individual's identity. The individual attempts to demonstrate his authenticity by making a phone call from an official HMRC number. Upon realizing that the individual is a fraud, the speaker vehemently criticizes him for his criminal activities before ending the call.\n",
      "\n",
      "Potential Fraud / Confidence Score:\n",
      "This seems to be a definite fraud case. Often, fraudsters pretend to be from a government entity, intimidate recipients, and make them pay in a rush without properly verifying the information. “HMRC” representative’s insistence on immediate action and his strangely detailed instructions on making payments also suggest deception. Confidence score: 95%.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11dafd7-4f50-4b97-a7f6-55bfb32cdbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# giving an id to each voice\n",
    "# extarct meaning from voice\n",
    "# detect if this person is trying to \n",
    "# person is lying about details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "545dbdd3-8f82-4da6-997f-30ed426aad95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 456: normal\tWhen're you guys getting back? G said you were thinking about not staying for mcr.normla\t\n",
      "\n",
      "Line 5928: \n",
      "\n",
      "Line 5929: \n",
      "\n",
      "Line 5930: \n",
      "\n",
      "Line 5931: \n",
      "\n",
      "Line 5932: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"F:/office_work/voice_fraud/fraud_call.file\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    \n",
    "for i, line in enumerate(lines):\n",
    "    if len(line.split('\\t')) != 2:\n",
    "        print(f\"Line {i+1}: {line}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c60fb0f3-8bbe-49cc-8f49-39434f4c17b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = pd.DataFrame(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70c9d817-36e6-47fd-abc7-76d5f037c6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fraud',\n",
       " 'hello, i m bank manager of SBI, ur debit card is about to expire would u want to issue new  card.\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0].split(\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f07f5e6-1b75-42a5-8187-3e30d36a5a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(r):\n",
    "    t = r[0].split(\"\\t\")\n",
    "    if len(t)!=2:\n",
    "        return \"none\",\"none\",0\n",
    "    else:\n",
    "        return t[0],t[1],len(t[1].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc837ac8-7621-4a72-b770-0434dfdb39e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = fraud.apply(pp,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "400d6697-27f7-4e7c-8c5c-a52f0033a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_calls = pd.DataFrame(list(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3b7165f-b145-44f5-9aee-6616c8885df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_calls.columns = ['label','text','length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2e9eafd-807c-42e5-b5b7-d65cfd5c6385",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_calls_fil = fraud_calls[~fraud_calls['length'].isin([0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60d4eb94-ceab-444d-acfe-ee339754a553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9989885367498315"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_calls_fil.shape[0]/fraud_calls.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "abe7e06b-23b5-4ccd-8fef-a32adc028fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71407486-8f1d-4a2e-884f-37950cb356b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>21</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>22</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>24</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>25</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>26</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>27</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>28</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>29</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>31</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>32</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>33</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>35</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>39</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>43</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>62</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    length  count\n",
       "33       1     40\n",
       "32       2     41\n",
       "26       3     94\n",
       "7        4    211\n",
       "3        5    382\n",
       "0        6    451\n",
       "1        7    433\n",
       "2        8    420\n",
       "4        9    317\n",
       "5       10    280\n",
       "6       11    260\n",
       "8       12    209\n",
       "9       13    193\n",
       "11      14    174\n",
       "10      15    183\n",
       "12      16    152\n",
       "16      17    132\n",
       "15      18    136\n",
       "18      19    129\n",
       "21      20    115\n",
       "24      21     99\n",
       "13      22    138\n",
       "22      23    108\n",
       "17      24    132\n",
       "19      25    122\n",
       "20      26    120\n",
       "14      27    137\n",
       "23      28    105\n",
       "25      29     97\n",
       "27      30     80\n",
       "29      31     57\n",
       "28      32     65\n",
       "31      33     42\n",
       "34      34     38\n",
       "30      35     44\n",
       "35      36     25\n",
       "36      37     19\n",
       "38      38     12\n",
       "37      39     18\n",
       "39      40     11\n",
       "41      41      6\n",
       "46      42      4\n",
       "40      43      9\n",
       "50      44      4\n",
       "58      45      3\n",
       "54      46      3\n",
       "43      47      4\n",
       "48      48      4\n",
       "42      49      4\n",
       "66      50      1\n",
       "53      52      3\n",
       "68      53      1\n",
       "49      54      4\n",
       "72      55      1\n",
       "44      56      4\n",
       "57      57      3\n",
       "51      58      3\n",
       "67      59      1\n",
       "56      60      3\n",
       "47      61      4\n",
       "45      62      4\n",
       "61      64      2\n",
       "69      66      1\n",
       "81      68      1\n",
       "76      69      1\n",
       "52      70      3\n",
       "55      71      3\n",
       "79      72      1\n",
       "63      76      2\n",
       "78      77      1\n",
       "59      79      3\n",
       "80      80      1\n",
       "82      88      1\n",
       "73      89      1\n",
       "71      94      1\n",
       "65      95      1\n",
       "62      96      2\n",
       "77      98      1\n",
       "74     103      1\n",
       "75     109      1\n",
       "60     125      2\n",
       "64     162      1\n",
       "70     171      1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(fraud_calls_fil['length'].value_counts()).reset_index().sort_values(by='length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afbd1b1-855d-47e3-8eee-f1730dd736ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sj = \"\"\"  [{\"key1\":\"value1\"},  {\"key2\":\"value2\"},\n",
    "{\"key3\":\"value3\"}]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sj = sj.strip()\n",
    "#assuming key does not have : in it\n",
    "if sj[0]==\"[\" and sj[-1]==\"]\":\n",
    "\n",
    "else:\n",
    "   if sj[0]==\"{\" and sj[-1]==\"}\":\n",
    "       sj = \"\"\"{  'key1':'val:,','ue1', ''key2':\"va',:lue2 \" ,key3: \"val..,,:':'\"\"''ue3\"}\"\"\"\n",
    "       sj = \"\"\"{}\"\"\"\n",
    "       sj = sj[1:-2]\n",
    "       \n",
    "   else:\n",
    "       print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80130fea-b0c6-4a15-9de9-c4f8829a96ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "give a list of keys\n",
    "keys enclosed in \"\" or '' brackets\n",
    "has 'key1'%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d91ceaf6-849e-401b-b67f-5b43be9d436e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bd1d63c-8612-4a6a-b63a-4c67c473f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def create_regex_for_rest_key(key: str) -> str:\n",
    "    # Escape the key to handle any special characters\n",
    "    # Construct the regex pattern\n",
    "    regex_pattern = r',\\s*[\"\\']' + str(key) + r'[\"\\']\\s*:'\n",
    "    \n",
    "    return regex_pattern\n",
    "\n",
    "def create_regex_for_first_key(key: str) -> str:\n",
    "    # Escape the key to handle any special characters\n",
    "    # Construct the regex pattern\n",
    "    regex_pattern = r'\\s*[\"\\']' + str(key) + r'[\"\\']\\s*:'\n",
    "    \n",
    "    return regex_pattern\n",
    "\n",
    "\n",
    "def split_string_by_regex(input_string, keys_list,first_key=\"\"):\n",
    "\n",
    "    if first_key==\"\":\n",
    "        first_key = keys_list[0]\n",
    "\n",
    "    \n",
    "    r1 = create_regex_for_first_key(first_key)\n",
    "\n",
    "    rs = []\n",
    "\n",
    "    for kl in keys_list:\n",
    "        if kl !=first_key:\n",
    "            r = create_regex_for_rest_key(first_key)\n",
    "            rs.append(r)\n",
    "\n",
    "\n",
    "    rs = [r1] + rs\n",
    "\n",
    "    regex_list = rs\n",
    "    print(regex_list)\n",
    "    # Combine all regex patterns into one by joining them with '|'\n",
    "    combined_regex = '|'.join(f'({regex})' for regex in regex_list)\n",
    "    \n",
    "    # Split the input string using the combined regex pattern\n",
    "    result = re.split(combined_regex, input_string)\n",
    "    \n",
    "    # Filter out empty strings from the result\n",
    "    result = [s for s in result if s]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c008fb47-593d-43b8-9a0e-953e361dd4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split_string_by_regex*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87a23420-5b41-4086-ab73-5254f471ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(,)(any number of whitespaces)(\"or')key(\"or')(any number of whitespaces)(:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb43f459-c577-44bb-8402-315d45e449c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key1': \"val:,','ue1\", 'key2': \"va',:lue2 \", 'key3': \"val..,,:':'''ue3\"}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj = \"\"\"{ \n",
    "'key1':\"val:,','ue1\",\n",
    "\"key2\":\"va',:lue2 \" ,\n",
    "\"key3\": \"val..,,:':'\"\"''ue3\"}\"\"\"\n",
    "import json, ast\n",
    "ast.literal_eval(sj)\n",
    "#sj.split(\"key1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "379fa5f1-561d-47ce-a1f9-9160296ab620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{ \\n\\'key1\\':\\'val:,\\',\\'ue1\\',\\n\\'key2\\':\"va\\',:lue2 \" ,\\n\\'key3\\': \"val..,,:\\':\\'\"\"\\'\\'ue3\"}'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r',\\s*[\"\\']' + str(\"key1\") + r'[\"\\']\\s*:',sj)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da79725a-b5b1-485c-849e-87fc440bfa55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\\\s*[\"\\\\\\']key1[\"\\\\\\']\\\\s*:', ',\\\\s*[\"\\\\\\']key1[\"\\\\\\']\\\\s*:', ',\\\\s*[\"\\\\\\']key1[\"\\\\\\']\\\\s*:']\n",
      "{\n",
      "##########\n",
      " \n",
      "'key1':\n",
      "##########\n",
      "'val:,','ue1',\n",
      "'key2':\"va',:lue2 \" ,\n",
      "'key3': \"val..,,:':'\"\"''ue3\"}\n",
      "##########\n"
     ]
    }
   ],
   "source": [
    "ss = split_string_by_regex(sj,['key1','key2','key3'])\n",
    "\n",
    "for s in ss:\n",
    "    print(s)\n",
    "    print(\"##########\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59a823b1-b153-46e9-832d-ecb295a69b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{  \\'key1\\':\\'val:,\\',\\'ue1\\', \\'\\'key2\\':\"va\\',:lue2 \" ,key3: \"val..,,:\\':\\'\"\"\\'\\'ue3\"}']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b10877d-3c0d-454c-b6a2-724b2f930c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_value()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personalEnv2",
   "language": "python",
   "name": "personalenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
